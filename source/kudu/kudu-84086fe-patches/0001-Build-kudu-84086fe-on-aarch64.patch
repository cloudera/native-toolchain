diff --git a/thirdparty/build-definitions.sh b/thirdparty/build-definitions.sh
index 4df64f678..e200b15fc 100644
--- a/thirdparty/build-definitions.sh
+++ b/thirdparty/build-definitions.sh
@@ -325,7 +325,7 @@ build_llvm() {
     -DLLVM_INCLUDE_EXAMPLES=OFF \
     -DLLVM_INCLUDE_TESTS=OFF \
     -DLLVM_INCLUDE_UTILS=OFF \
-    -DLLVM_TARGETS_TO_BUILD=X86 \
+    -DLLVM_TARGETS_TO_BUILD="X86;AArch64" \
     -DLLVM_ENABLE_RTTI=ON \
     -DCMAKE_CXX_FLAGS="$CLANG_CXXFLAGS" \
     -DCMAKE_EXE_LINKER_FLAGS="$CLANG_LDFLAGS" \
@@ -445,7 +445,8 @@ build_gperftools() {
     $GPERFTOOLS_SOURCE/configure \
     --enable-frame-pointers \
     --with-pic \
-    --prefix=$PREFIX
+    --prefix=$PREFIX \
+    --enable-emergency-malloc
   fixup_libtool
   make -j$PARALLEL $EXTRA_MAKEFLAGS install
   popd
@@ -565,7 +566,11 @@ build_bitshuffle() {
   # suffix the AVX2 symbols with '_avx2'. OSX doesn't have objcopy, so we only
   # do this trick on Linux.
   if [ -n "$OS_LINUX" ]; then
-    arches="default avx2"
+    if [[ "$ARCH_NAME" == "aarch64" ]]; then
+      arches="default"
+    else
+      arches="default avx2"
+    fi
   else
     arches="default"
   fi
diff --git a/thirdparty/download-thirdparty.sh b/thirdparty/download-thirdparty.sh
index dd5167846..f8a7d9c3c 100755
--- a/thirdparty/download-thirdparty.sh
+++ b/thirdparty/download-thirdparty.sh
@@ -297,12 +297,13 @@ fetch_and_patch \
  $CURL_PATCHLEVEL \
  "autoreconf -fvi"

-CRCUTIL_PATCHLEVEL=1
+CRCUTIL_PATCHLEVEL=2
 fetch_and_patch \
  crcutil-${CRCUTIL_VERSION}.tar.gz \
  $CRCUTIL_SOURCE \
  $CRCUTIL_PATCHLEVEL \
- "patch -p0 < $TP_DIR/patches/crcutil-fix-libtoolize-on-osx.patch"
+ "patch -p0 < $TP_DIR/patches/crcutil-fix-libtoolize-on-osx.patch" \
+ "patch -p0 < $TP_DIR/patches/crcutil-fix-on-aarch64.patch"

 LIBUNWIND_PATCHLEVEL=1
 fetch_and_patch \
diff --git a/CMakeLists.txt b/CMakeLists.txt
index d53f81ecc..e29cf8eff 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -124,7 +124,10 @@ endif()

 # compiler flags that are common across debug/release builds
 #  -msse4.2: Enable sse4.2 compiler intrinsics.
-set(CXX_COMMON_FLAGS "-msse4.2")
+execute_process(COMMAND uname -p OUTPUT_VARIABLE ARCH_NAME)
+if (NOT "${ARCH_NAME}" MATCHES "aarch64")
+  set(CXX_COMMON_FLAGS "-msse4.2")
+endif()
 #  -Wall: Enable all warnings.
 set(CXX_COMMON_FLAGS "${CXX_COMMON_FLAGS} -Wall")
 #  -Wno-sign-compare: suppress warnings for comparison between signed and unsigned
diff --git a/thirdparty/patches/crcutil-fix-on-aarch64.patch b/thirdparty/patches/crcutil-fix-on-aarch64.patch
new file mode 100644
index 000000000..fcf1bba6a
--- /dev/null
+++ b/thirdparty/patches/crcutil-fix-on-aarch64.patch
@@ -0,0 +1,104 @@
+--- autogen.sh
++++ autogen.sh
+@@ -91,6 +91,10 @@ elif [[ "$IS_CLANG" = "1" ]]; then
+   crcutil_flags="${crcutil_flags} -msse4.2"
+ fi
+
++if [[ "$ARCH_NAME" == "aarch64" ]]; then
++  crcutil_flags="-DCRCUTIL_USE_MM_CRC32=1 -Wall -march=armv8-a+crc -Icode -Iexamples -Itests -O3"
++fi
++
+ echo>>${target} "AM_CXXFLAGS=${crcutil_flags}"
+ echo>>${target} 'AM_CFLAGS=$(AM_CXXFLAGS)'
+
+--- code/crc32c_sse4.cc
++++ code/crc32c_sse4.cc
+@@ -18,7 +18,7 @@
+
+ #include "crc32c_sse4.h"
+
+-#if HAVE_I386 || HAVE_AMD64
++#if HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64
+
+ namespace crcutil {
+
+@@ -363,4 +363,4 @@ void RollingCrc32cSSE4::Init(const Crc32cSSE4 &crc,
+
+ }  // namespace crcutil
+
+-#endif  // HAVE_I386 || HAVE_AMD64
++#endif  // HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64
+--- code/crc32c_sse4.h
++++ code/crc32c_sse4.h
+@@ -22,7 +22,7 @@
+ #include "gf_util.h"              // base types, gf_util class, etc.
+ #include "crc32c_sse4_intrin.h"   // _mm_crc32_u* intrinsics
+
+-#if HAVE_I386 || HAVE_AMD64
++#if HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64
+
+ #if CRCUTIL_USE_MM_CRC32
+
+@@ -247,6 +247,6 @@ class RollingCrc32cSSE4 {
+
+ }  // namespace crcutil
+
+-#endif  // HAVE_I386 || HAVE_AMD64
++#endif  // HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64
+
+ #endif  // CRCUTIL_CRC32C_SSE4_H_
+--- code/crc32c_sse4_intrin.h
++++ code/crc32c_sse4_intrin.h
+@@ -20,7 +20,7 @@
+ #include "platform.h"
+ #include "base_types.h"
+
+-#if CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64)
++#if CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64)
+
+ #if defined(_MSC_VER) || defined(__SSE4_2__)
+
+@@ -94,6 +94,6 @@ __forceinline uint32 _mm_crc32_u8(uint32 crc, uint8 value) {
+
+ #endif
+
+-#endif  // CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64)
++#endif  // CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64)
+
+ #endif  // CRCUTIL_CRC32C_SSE4_INTRIN_H_
+--- code/platform.h
++++ code/platform.h
+@@ -45,6 +45,13 @@
+ #endif  // defined(__amd64__) || defined(_M_AMD64)
+ #endif  // defined(HAVE_AMD64)
+
++#if !defined(HAVE_AARCH64)
++#if defined(__aarch64__)
++#define HAVE_AARCH64 1
++#else
++#define HAVE_AARCH64 0
++#endif  // defined(__aarch64__)
++#endif  // defined(HAVE_AARCH64)
+
+ #if HAVE_AMD64 || HAVE_I386
+ #if defined(_MSC_VER)
+--- examples/interface.cc
++++ examples/interface.cc
+@@ -268,7 +268,7 @@ CRC *CRC::Create(UINT64 poly_lo,
+ #endif  // !HAVE_SSE2
+   }
+
+-#if CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64)
++#if CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64)
+   if (use_sse4_2 &&
+       degree == Crc32cSSE4::FixedDegree() &&
+       poly_lo == Crc32cSSE4::FixedGeneratingPolynomial() &&
+@@ -284,7 +284,7 @@ CRC *CRC::Create(UINT64 poly_lo,
+         static_cast<size_t>(roll_length),
+         allocated_memory);
+   }
+-#endif  // CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64)
++#endif  // CRCUTIL_USE_MM_CRC32 && (HAVE_I386 || HAVE_AMD64 || HAVE_AARCH64)
+
+   if (poly_hi != 0 || (degree != 64 && (poly_lo >> degree) != 0)) {
+     return NULL;
diff --git a/src/kudu/gutil/spinlock_linux-inl.h b/src/kudu/gutil/spinlock_linux-inl.h
index 41ef03ac6..78a6f657a 100644
--- a/src/kudu/gutil/spinlock_linux-inl.h
+++ b/src/kudu/gutil/spinlock_linux-inl.h
@@ -42,6 +42,9 @@
 #define FUTEX_WAKE 1
 #define FUTEX_PRIVATE_FLAG 128

+// Note: Instead of making direct system calls that are inlined, we rely
+//       on the syscall() function in glibc to do the right thing.
+
 static bool have_futex;
 static int futex_private_flag = FUTEX_PRIVATE_FLAG;

@@ -51,15 +54,10 @@ static struct InitModule {
     int x = 0;
     // futexes are ints, so we can use them only when
     // that's the same size as the lockword_ in SpinLock.
-#ifdef __arm__
-    // ARM linux doesn't support sys_futex1(void*, int, int, struct timespec*);
-    have_futex = 0;
-#else
-    have_futex = (sizeof (Atomic32) == sizeof (int) &&
-                  sys_futex(&x, FUTEX_WAKE, 1, 0) >= 0);
-#endif
-    if (have_futex &&
-        sys_futex(&x, FUTEX_WAKE | futex_private_flag, 1, 0) < 0) {
+    have_futex = (sizeof(Atomic32) == sizeof(int) &&
+                  syscall(__NR_futex, &x, FUTEX_WAKE, 1, NULL, NULL, 0) >= 0);
+    if (have_futex && syscall(__NR_futex, &x, FUTEX_WAKE | futex_private_flag,
+                              1, NULL, NULL, 0) < 0) {
       futex_private_flag = 0;
     }
   }
@@ -83,9 +81,9 @@ void SpinLockDelay(volatile Atomic32 *w, int32 value, int loop) {
     }
     if (have_futex) {
       tm.tv_nsec *= 16;  // increase the delay; we expect explicit wakeups
-      sys_futex(reinterpret_cast<int *>(const_cast<Atomic32 *>(w)),
-                FUTEX_WAIT | futex_private_flag,
-                value, reinterpret_cast<struct kernel_timespec *>(&tm));
+      syscall(__NR_futex, reinterpret_cast<int*>(const_cast<Atomic32*>(w)),
+              FUTEX_WAIT | futex_private_flag, value,
+              reinterpret_cast<struct kernel_timespec*>(&tm), NULL, 0);
     } else {
       nanosleep(&tm, NULL);
     }
@@ -95,8 +93,8 @@ void SpinLockDelay(volatile Atomic32 *w, int32 value, int loop) {

 void SpinLockWake(volatile Atomic32 *w, bool all) {
   if (have_futex) {
-    sys_futex(reinterpret_cast<int *>(const_cast<Atomic32 *>(w)),
-              FUTEX_WAKE | futex_private_flag, all? INT_MAX : 1, 0);
+    syscall(__NR_futex, reinterpret_cast<int*>(const_cast<Atomic32*>(w)),
+            FUTEX_WAKE | futex_private_flag, all ? INT_MAX : 1, NULL, NULL, 0);
   }
 }

diff --git a/src/kudu/gutil/port.h b/src/kudu/gutil/port.h
index 0cf416ee3..730937946 100644
--- a/src/kudu/gutil/port.h
+++ b/src/kudu/gutil/port.h
@@ -324,6 +324,8 @@ inline void* memrchr(const void* bytes, int find_char, size_t len) {
 // TODO(user) This is the L1 D-cache line size of our Power7 machines.
 // Need to check if this is appropriate for other PowerPC64 systems.
 #define CACHELINE_SIZE 128
+#elif defined(__aarch64__)
+#define CACHELINE_SIZE 64
 #elif defined(__arm__)
 // Cache line sizes for ARM: These values are not strictly correct since
 // cache line sizes depend on implementations, not architectures.  There
diff --git a/src/kudu/gutil/cycleclock-inl.h b/src/kudu/gutil/cycleclock-inl.h
index 77385923a..fa43ffe4d 100644
--- a/src/kudu/gutil/cycleclock-inl.h
+++ b/src/kudu/gutil/cycleclock-inl.h
@@ -147,7 +147,20 @@ inline int64 CycleClock::Now() {
 }

 // ----------------------------------------------------------------
-#elif defined(ARMV6)  // V6 is the earliest arm that has a standard cyclecount
+#elif defined(__aarch64__)
+#include "kudu/gutil/sysinfo.h"
+inline int64 CycleClock::Now() {
+  // System timer of ARMv8 runs at a different frequency than the CPU's.
+  // The frequency is fixed, typically in the range 1-50MHz.  It can be
+  // read at CNTFRQ special register.  We assume the OS has set up
+  // the virtual timer properly.
+  int64_t virtual_timer_value;
+  asm volatile("mrs %0, cntvct_el0" : "=r"(virtual_timer_value));
+  return virtual_timer_value;
+}
+
+// ----------------------------------------------------------------
+#elif defined(ARMV6)   // V6 is the earliest arm that has a standard cyclecount
 #include "kudu/gutil/sysinfo.h"
 inline int64 CycleClock::Now() {
   uint32 pmccntr;
diff --git a/src/kudu/gutil/linux_syscall_support.h b/src/kudu/gutil/linux_syscall_support.h
index 5476d0bfa..199061a90 100644
--- a/src/kudu/gutil/linux_syscall_support.h
+++ b/src/kudu/gutil/linux_syscall_support.h
@@ -1,3 +1,4 @@
+// -*- Mode: C++; c-basic-offset: 2; indent-tabs-mode: nil -*-
 /* Copyright (c) 2005-2008, Google Inc.
  * All rights reserved.
  *
@@ -69,15 +70,74 @@
  * This file defines a few internal symbols that all start with "LSS_".
  * Do not access these symbols from outside this file. They are not part
  * of the supported API.
+ *
+ * NOTE: This is a stripped down version of the official opensource
+ * version of linux_syscall_support.h, which lives at
+ *    http://code.google.com/p/linux-syscall-support/
+ * It includes only the syscalls that are used in perftools, plus a
+ * few extra.  Here's the breakdown:
+ * 1) Perftools uses these: grep -rho 'sys_[a-z0-9_A-Z]* *(' src | sort -u
+ *      sys__exit(
+ *      sys_clone(
+ *      sys_close(
+ *      sys_fcntl(
+ *      sys_fstat(
+ *      sys_futex(
+ *      sys_getcpu(
+ *      sys_getdents64(
+ *      sys_getppid(
+ *      sys_gettid(
+ *      sys_lseek(
+ *      sys_mmap(
+ *      sys_mremap(
+ *      sys_munmap(
+ *      sys_open(
+ *      sys_pipe(
+ *      sys_prctl(
+ *      sys_ptrace(
+ *      sys_ptrace_detach(
+ *      sys_read(
+ *      sys_sched_yield(
+ *      sys_sigaction(
+ *      sys_sigaltstack(
+ *      sys_sigdelset(
+ *      sys_sigfillset(
+ *      sys_sigprocmask(
+ *      sys_socket(
+ *      sys_stat(
+ *      sys_waitpid(
+ * 2) These are used as subroutines of the above:
+ *      sys_getpid       -- gettid
+ *      sys_kill         -- ptrace_detach
+ *      sys_restore      -- sigaction
+ *      sys_restore_rt   -- sigaction
+ *      sys_socketcall   -- socket
+ *      sys_wait4        -- waitpid
+ * 3) I left these in even though they're not used.  They either
+ * complement the above (write vs read) or are variants (rt_sigaction):
+ *      sys_fstat64
+ *      sys_llseek
+ *      sys_mmap2
+ *      sys_openat
+ *      sys_getdents
+ *      sys_rt_sigaction
+ *      sys_rt_sigprocmask
+ *      sys_sigaddset
+ *      sys_sigemptyset
+ *      sys_stat64
+ *      sys_write
  */
 #ifndef SYS_LINUX_SYSCALL_SUPPORT_H
 #define SYS_LINUX_SYSCALL_SUPPORT_H

-/* We currently only support x86-32, x86-64, ARM, MIPS, and PPC on Linux.
+/* We currently only support x86-32, x86-64, ARM, MIPS, PPC/PPC64, Aarch64, s390 and s390x
+ * on Linux.
  * Porting to other related platforms should not be difficult.
  */
 #if (defined(__i386__) || defined(__x86_64__) || defined(__arm__) || \
-     defined(__mips__) || defined(__PPC__)) && defined(__linux)
+     defined(__mips__) || defined(__PPC__) || \
+     defined(__aarch64__) || defined(__s390__)) \
+  && (defined(__linux))

 #ifndef SYS_CPLUSPLUS
 #ifdef __cplusplus
@@ -91,6 +151,8 @@ extern "C" {
 #include <errno.h>
 #include <signal.h>
 #include <stdarg.h>
+#include <stddef.h>
+#include <stdint.h>
 #include <string.h>
 #include <sys/ptrace.h>
 #include <sys/resource.h>
@@ -100,6 +162,7 @@ extern "C" {
 #include <unistd.h>
 #include <linux/unistd.h>
 #include <endian.h>
+#include <fcntl.h>

 #ifdef __mips__
 /* Include definitions of the ABI currently in use.                          */
@@ -154,36 +217,6 @@ struct kernel_dirent {
   char               d_name[256];
 };

-/* include/linux/uio.h                                                       */
-struct kernel_iovec {
-  void               *iov_base;
-  unsigned long      iov_len;
-};
-
-/* include/linux/socket.h                                                    */
-struct kernel_msghdr {
-  void               *msg_name;
-  int                msg_namelen;
-  struct kernel_iovec*msg_iov;
-  unsigned long      msg_iovlen;
-  void               *msg_control;
-  unsigned long      msg_controllen;
-  unsigned           msg_flags;
-};
-
-/* include/asm-generic/poll.h                                                */
-struct kernel_pollfd {
-  int                fd;
-  short              events;
-  short              revents;
-};
-
-/* include/linux/resource.h                                                  */
-struct kernel_rlimit {
-  unsigned long      rlim_cur;
-  unsigned long      rlim_max;
-};
-
 /* include/linux/time.h                                                      */
 struct kernel_timespec {
   long               tv_sec;
@@ -216,26 +249,14 @@ struct kernel_rusage {
   long               ru_nivcsw;
 };

-/* include/linux/capablilty.h                                                */
-struct kernel_cap_user_header {
-  unsigned int version;
-  int pid;
-};
-
-struct kernel_cap_user_data {
-  unsigned int effective;
-  unsigned int permitted;
-  unsigned int inheritable;
-};
-
-struct siginfo;
-#if defined(__i386__) || defined(__arm__) || defined(__PPC__)
+#if defined(__i386__) || defined(__arm__) \
+  || defined(__PPC__) || (defined(__s390__) && !defined(__s390x__))

 /* include/asm-{arm,i386,mips,ppc}/signal.h                                  */
 struct kernel_old_sigaction {
   union {
     void             (*sa_handler_)(int);
-    void             (*sa_sigaction_)(int, struct siginfo *, void *);
+    void             (*sa_sigaction_)(int, siginfo_t *, void *);
   };
   unsigned long      sa_mask;
   unsigned long      sa_flags;
@@ -243,6 +264,8 @@ struct kernel_old_sigaction {
 } __attribute__((packed,aligned(4)));
 #elif (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI32)
   #define kernel_old_sigaction kernel_sigaction
+#elif defined(__aarch64__)
+  // No kernel_old_sigaction defined for arm64.
 #endif

 /* Some kernel functions (e.g. sigaction() in 2.6.23) require that the
@@ -266,19 +289,19 @@ struct kernel_sigset_t {
                     (8*sizeof(unsigned long))];
 };

-/* include/asm-{arm,i386,mips,x86_64,ppc}/signal.h                           */
+/* include/asm-{arm,generic,i386,mips,x86_64,ppc}/signal.h                   */
 struct kernel_sigaction {
 #ifdef __mips__
   unsigned long      sa_flags;
   union {
     void             (*sa_handler_)(int);
-    void             (*sa_sigaction_)(int, struct siginfo *, void *);
+    void             (*sa_sigaction_)(int, siginfo_t *, void *);
   };
   struct kernel_sigset_t sa_mask;
 #else
   union {
     void             (*sa_handler_)(int);
-    void             (*sa_sigaction_)(int, struct siginfo *, void *);
+    void             (*sa_sigaction_)(int, siginfo_t *, void *);
   };
   unsigned long      sa_flags;
   void               (*sa_restorer)(void);
@@ -286,15 +309,9 @@ struct kernel_sigaction {
 #endif
 };

-/* include/linux/socket.h                                                    */
-struct kernel_sockaddr {
-  unsigned short     sa_family;
-  char               sa_data[14];
-};
-
-/* include/asm-{arm,i386,mips,ppc}/stat.h                                    */
+/* include/asm-{arm,i386,mips,ppc,s390}/stat.h                               */
 #ifdef __mips__
-#if _MIPS_SIM == _MIPS_SIM_ABI64
+#if (_MIPS_SIM == _MIPS_SIM_ABI64 || _MIPS_SIM == _MIPS_SIM_NABI32)
 struct kernel_stat {
 #else
 struct kernel_stat64 {
@@ -319,27 +336,25 @@ struct kernel_stat64 {
   unsigned           __pad2;
   unsigned long long st_blocks;
 };
-#elif defined __PPC__ && !defined __PPC64__
+#elif defined __PPC__
 struct kernel_stat64 {
   unsigned long long st_dev;
   unsigned long long st_ino;
-  unsigned           st_mode;
   unsigned           st_nlink;
+  unsigned           st_mode;
   unsigned           st_uid;
   unsigned           st_gid;
+  int                __pad2;
   unsigned long long st_rdev;
-  unsigned short int __pad2;
   long long          st_size;
-  long               st_blksize;
+  long long          st_blksize;
   long long          st_blocks;
-  long               st_atime_;
-  unsigned long      st_atime_nsec_;
-  long               st_mtime_;
-  unsigned long      st_mtime_nsec_;
-  long               st_ctime_;
-  unsigned long      st_ctime_nsec_;
+  kernel_timespec    st_atim;
+  kernel_timespec    st_mtim;
+  kernel_timespec    st_ctim;
   unsigned long      __unused4;
   unsigned long      __unused5;
+  unsigned long      __unused6;
 };
 #else
 struct kernel_stat64 {
@@ -365,7 +380,7 @@ struct kernel_stat64 {
 };
 #endif

-/* include/asm-{arm,i386,mips,x86_64,ppc}/stat.h                             */
+/* include/asm-{arm,generic,i386,mips,x86_64,ppc,s390}/stat.h                     */
 #if defined(__i386__) || defined(__arm__)
 struct kernel_stat {
   /* The kernel headers suggest that st_dev and st_rdev should be 32bit
@@ -396,55 +411,47 @@ struct kernel_stat {
 };
 #elif defined(__x86_64__)
 struct kernel_stat {
-  unsigned long      st_dev;
-  unsigned long      st_ino;
-  unsigned long      st_nlink;
+  uint64_t           st_dev;
+  uint64_t           st_ino;
+  uint64_t           st_nlink;
   unsigned           st_mode;
   unsigned           st_uid;
   unsigned           st_gid;
   unsigned           __pad0;
-  unsigned long      st_rdev;
-  long               st_size;
-  long               st_blksize;
-  long               st_blocks;
-  unsigned long      st_atime_;
-  unsigned long      st_atime_nsec_;
-  unsigned long      st_mtime_;
-  unsigned long      st_mtime_nsec_;
-  unsigned long      st_ctime_;
-  unsigned long      st_ctime_nsec_;
-  long               __unused[3];
+  uint64_t           st_rdev;
+  int64_t            st_size;
+  int64_t            st_blksize;
+  int64_t            st_blocks;
+  uint64_t           st_atime_;
+  uint64_t           st_atime_nsec_;
+  uint64_t           st_mtime_;
+  uint64_t           st_mtime_nsec_;
+  uint64_t           st_ctime_;
+  uint64_t           st_ctime_nsec_;
+  int64_t            __unused[3];
 };
 #elif defined(__PPC__)
 struct kernel_stat {
-  unsigned long      st_dev;
-  unsigned long      st_ino;      // ino_t
-#ifdef __PPC64__
-  unsigned long      st_nlink;    // nlink_t
-  unsigned int       st_mode;     // mode_t
-#else
-  unsigned int       st_mode;     // mode_t
-  unsigned short     st_nlink;    // nlink_t
-#endif
-  unsigned int       st_uid;      // uid_t
-  unsigned int       st_gid;      // gid_t
-  unsigned long      st_rdev;
-  long               st_size;     // off_t
+  unsigned long long st_dev;
+  unsigned long      st_ino;
+  unsigned long      st_nlink;
+  unsigned long      st_mode;
+  unsigned           st_uid;
+  unsigned           st_gid;
+  int                __pad2;
+  unsigned long long st_rdev;
+  long               st_size;
   unsigned long      st_blksize;
   unsigned long      st_blocks;
-  unsigned long      st_atime_;
-  unsigned long      st_atime_nsec_;
-  unsigned long      st_mtime_;
-  unsigned long      st_mtime_nsec_;
-  unsigned long      st_ctime_;
-  unsigned long      st_ctime_nsec_;
+  kernel_timespec    st_atim;
+  kernel_timespec    st_mtim;
+  kernel_timespec    st_ctim;
   unsigned long      __unused4;
   unsigned long      __unused5;
-#ifdef __PPC64__
   unsigned long      __unused6;
-#endif
 };
-#elif (defined(__mips__) && _MIPS_SIM != _MIPS_SIM_ABI64)
+#elif defined(__mips__) \
+       && !(_MIPS_SIM == _MIPS_SIM_ABI64 || _MIPS_SIM == _MIPS_SIM_NABI32)
 struct kernel_stat {
   unsigned           st_dev;
   int                st_pad1[3];
@@ -467,145 +474,90 @@ struct kernel_stat {
   int                st_blocks;
   int                st_pad4[14];
 };
-#endif
-
-/* include/asm-{arm,i386,mips,x86_64,ppc}/statfs.h                           */
-#ifdef __mips__
-#if _MIPS_SIM != _MIPS_SIM_ABI64
-struct kernel_statfs64 {
-  unsigned long      f_type;
-  unsigned long      f_bsize;
-  unsigned long      f_frsize;
-  unsigned long      __pad;
-  unsigned long long f_blocks;
-  unsigned long long f_bfree;
-  unsigned long long f_files;
-  unsigned long long f_ffree;
-  unsigned long long f_bavail;
-  struct { int val[2]; } f_fsid;
-  unsigned long      f_namelen;
-  unsigned long      f_spare[6];
-};
-#endif
-#elif !defined(__x86_64__)
-struct kernel_statfs64 {
-  unsigned long      f_type;
-  unsigned long      f_bsize;
-  unsigned long long f_blocks;
-  unsigned long long f_bfree;
-  unsigned long long f_bavail;
-  unsigned long long f_files;
-  unsigned long long f_ffree;
-  struct { int val[2]; } f_fsid;
-  unsigned long      f_namelen;
-  unsigned long      f_frsize;
-  unsigned long      f_spare[5];
-};
-#endif
-
-/* include/asm-{arm,i386,mips,x86_64,ppc,generic}/statfs.h                   */
-#ifdef __mips__
-struct kernel_statfs {
-  long               f_type;
-  long               f_bsize;
-  long               f_frsize;
-  long               f_blocks;
-  long               f_bfree;
-  long               f_files;
-  long               f_ffree;
-  long               f_bavail;
-  struct { int val[2]; } f_fsid;
-  long               f_namelen;
-  long               f_spare[6];
-};
-#else
-struct kernel_statfs {
-  /* x86_64 actually defines all these fields as signed, whereas all other  */
-  /* platforms define them as unsigned. Leaving them at unsigned should not */
-  /* cause any problems.                                                    */
-  unsigned long      f_type;
-  unsigned long      f_bsize;
-  unsigned long      f_blocks;
-  unsigned long      f_bfree;
-  unsigned long      f_bavail;
-  unsigned long      f_files;
-  unsigned long      f_ffree;
-  struct { int val[2]; } f_fsid;
-  unsigned long      f_namelen;
-  unsigned long      f_frsize;
-  unsigned long      f_spare[5];
+#elif defined(__aarch64__)
+struct kernel_stat {
+  unsigned long      st_dev;
+  unsigned long      st_ino;
+  unsigned int       st_mode;
+  unsigned int       st_nlink;
+  unsigned int       st_uid;
+  unsigned int       st_gid;
+  unsigned long      st_rdev;
+  unsigned long      __pad1;
+  long               st_size;
+  int                st_blksize;
+  int                __pad2;
+  long               st_blocks;
+  long               st_atime_;
+  unsigned long      st_atime_nsec_;
+  long               st_mtime_;
+  unsigned long      st_mtime_nsec_;
+  long               st_ctime_;
+  unsigned long      st_ctime_nsec_;
+  unsigned int       __unused4;
+  unsigned int       __unused5;
 };
-#endif
-
-#if defined(__i386__) || defined(__x86_64__) || defined(__arm__) || \
-    defined(__PPC__)
-/* include/linux/aio_abi.h                                                   */
-/* Layout depends on big/little endian.                                      */
-struct kernel_iocb {
-  unsigned long long aio_data;
-  unsigned int       aio_key;
-  unsigned int       aio_reserved;
-  unsigned short     aio_lio_opcode;
-           short     aio_reqprio;
-  unsigned int       aio_filedes;
-  unsigned long long aio_buf;
-  unsigned long long aio_nbytes;
-  unsigned long long aio_offset;
-  unsigned long long aio_reserved2;
-  unsigned int       aio_flags;
-  unsigned int       aio_resfd;
+#elif defined(__s390x__)
+struct kernel_stat {
+  unsigned long      st_dev;
+  unsigned long      st_ino;
+  unsigned long      st_nlink;
+  unsigned int       st_mode;
+  unsigned int       st_uid;
+  unsigned int       st_gid;
+  unsigned int       __pad1;
+  unsigned long      st_rdev;
+  unsigned long      st_size;
+  unsigned long      st_atime_;
+  unsigned long      st_atime_nsec_;
+  unsigned long      st_mtime_;
+  unsigned long      st_mtime_nsec_;
+  unsigned long      st_ctime_;
+  unsigned long      st_ctime_nsec_;
+  unsigned long      st_blksize;
+  long               st_blocks;
+  unsigned long      __unused[3];
 };
-#elif defined(__PPC__)
-struct kernel_iocb {
-  unsigned long long aio_data;
-  unsigned int       aio_reserved;
-  unsigned int       aio_key;
-  unsigned short     aio_lio_opcode;
-           short     aio_reqprio;
-  unsigned int       aio_fildes;
-  unsigned long long aio_buf;
-  unsigned long long aio_nbytes;
-  unsigned long long aio_offset;
-  unsigned long long aio_reserved2;
-  unsigned int       aio_flags;
-  unsigned int       aio_resfd;
+#elif defined(__s390__)
+struct kernel_stat {
+  unsigned short     st_dev;
+  unsigned short     __pad1;
+  unsigned long      st_ino;
+  unsigned short     st_mode;
+  unsigned short     st_nlink;
+  unsigned short     st_uid;
+  unsigned short     st_gid;
+  unsigned short     st_rdev;
+  unsigned short     __pad2;
+  unsigned long      st_size;
+  unsigned long      st_blksize;
+  unsigned long      st_blocks;
+  unsigned long      st_atime_;
+  unsigned long      st_atime_nsec_;
+  unsigned long      st_mtime_;
+  unsigned long      st_mtime_nsec_;
+  unsigned long      st_ctime_;
+  unsigned long      st_ctime_nsec_;
+  unsigned long      __unused4;
+  unsigned long      __unused5;
 };
 #endif

-/* include/linux/aio_abi.h                                                   */
-struct kernel_io_event {
-  unsigned long long data;
-  unsigned long long obj;
-           long long res;
-           long long res2;
-};

 /* Definitions missing from the standard header files                        */
 #ifndef O_DIRECTORY
-#if defined(__arm__) || defined(__PPC_)
+#if defined(__arm__)
 #define O_DIRECTORY             0040000
 #else
 #define O_DIRECTORY             0200000
 #endif
 #endif
-#ifndef NT_PRXFPREG
-#define NT_PRXFPREG             0x46e62b7f
-#endif
-#ifndef PTRACE_GETFPXREGS
-#define PTRACE_GETFPXREGS       ((enum __ptrace_request)18)
-#endif
 #ifndef PR_GET_DUMPABLE
 #define PR_GET_DUMPABLE         3
 #endif
 #ifndef PR_SET_DUMPABLE
 #define PR_SET_DUMPABLE         4
 #endif
-#ifndef PR_GET_SECCOMP
-#define PR_GET_SECCOMP          21
-#endif
-#ifndef PR_SET_SECCOMP
-#define PR_SET_SECCOMP          22
-#endif
 #ifndef AT_FDCWD
 #define AT_FDCWD                (-100)
 #endif
@@ -621,126 +573,11 @@ struct kernel_io_event {
 #ifndef SA_RESTORER
 #define SA_RESTORER             0x04000000
 #endif
-#ifndef CPUCLOCK_PROF
-#define CPUCLOCK_PROF           0
-#endif
-#ifndef CPUCLOCK_VIRT
-#define CPUCLOCK_VIRT           1
-#endif
-#ifndef CPUCLOCK_SCHED
-#define CPUCLOCK_SCHED          2
-#endif
-#ifndef CPUCLOCK_PERTHREAD_MASK
-#define CPUCLOCK_PERTHREAD_MASK 4
-#endif
-#ifndef MAKE_PROCESS_CPUCLOCK
-#define MAKE_PROCESS_CPUCLOCK(pid, clock)                                     \
-        ((~(int)(pid) << 3) | (int)(clock))
-#endif
-#ifndef MAKE_THREAD_CPUCLOCK
-#define MAKE_THREAD_CPUCLOCK(tid, clock)                                      \
-        ((~(int)(tid) << 3) | (int)((clock) | CPUCLOCK_PERTHREAD_MASK))
-#endif
-
-#ifndef FUTEX_WAIT
-#define FUTEX_WAIT                0
-#endif
-#ifndef FUTEX_WAKE
-#define FUTEX_WAKE                1
-#endif
-#ifndef FUTEX_FD
-#define FUTEX_FD                  2
-#endif
-#ifndef FUTEX_REQUEUE
-#define FUTEX_REQUEUE             3
-#endif
-#ifndef FUTEX_CMP_REQUEUE
-#define FUTEX_CMP_REQUEUE         4
-#endif
-#ifndef FUTEX_WAKE_OP
-#define FUTEX_WAKE_OP             5
-#endif
-#ifndef FUTEX_LOCK_PI
-#define FUTEX_LOCK_PI             6
-#endif
-#ifndef FUTEX_UNLOCK_PI
-#define FUTEX_UNLOCK_PI           7
-#endif
-#ifndef FUTEX_TRYLOCK_PI
-#define FUTEX_TRYLOCK_PI          8
-#endif
-#ifndef FUTEX_PRIVATE_FLAG
-#define FUTEX_PRIVATE_FLAG        128
-#endif
-#ifndef FUTEX_CMD_MASK
-#define FUTEX_CMD_MASK            ~FUTEX_PRIVATE_FLAG
-#endif
-#ifndef FUTEX_WAIT_PRIVATE
-#define FUTEX_WAIT_PRIVATE        (FUTEX_WAIT | FUTEX_PRIVATE_FLAG)
-#endif
-#ifndef FUTEX_WAKE_PRIVATE
-#define FUTEX_WAKE_PRIVATE        (FUTEX_WAKE | FUTEX_PRIVATE_FLAG)
-#endif
-#ifndef FUTEX_REQUEUE_PRIVATE
-#define FUTEX_REQUEUE_PRIVATE     (FUTEX_REQUEUE | FUTEX_PRIVATE_FLAG)
-#endif
-#ifndef FUTEX_CMP_REQUEUE_PRIVATE
-#define FUTEX_CMP_REQUEUE_PRIVATE (FUTEX_CMP_REQUEUE | FUTEX_PRIVATE_FLAG)
-#endif
-#ifndef FUTEX_WAKE_OP_PRIVATE
-#define FUTEX_WAKE_OP_PRIVATE     (FUTEX_WAKE_OP | FUTEX_PRIVATE_FLAG)
-#endif
-#ifndef FUTEX_LOCK_PI_PRIVATE
-#define FUTEX_LOCK_PI_PRIVATE     (FUTEX_LOCK_PI | FUTEX_PRIVATE_FLAG)
-#endif
-#ifndef FUTEX_UNLOCK_PI_PRIVATE
-#define FUTEX_UNLOCK_PI_PRIVATE   (FUTEX_UNLOCK_PI | FUTEX_PRIVATE_FLAG)
-#endif
-#ifndef FUTEX_TRYLOCK_PI_PRIVATE
-#define FUTEX_TRYLOCK_PI_PRIVATE  (FUTEX_TRYLOCK_PI | FUTEX_PRIVATE_FLAG)
-#endif
-
-
-#if defined(__x86_64__)
-#ifndef ARCH_SET_GS
-#define ARCH_SET_GS             0x1001
-#endif
-#ifndef ARCH_GET_GS
-#define ARCH_GET_GS             0x1004
-#endif
-#endif

 #if defined(__i386__)
-#ifndef __NR_mount
-#define __NR_mount               21
-#endif
-#ifndef __NR_setgroups32
-#define __NR_setgroups32         81
-#endif
-#ifndef __NR_quotactl
-#define __NR_quotactl           131
-#endif
-#ifndef __NR_setresuid
-#define __NR_setresuid          164
-#define __NR_getresuid          165
-#define __NR_setresgid          170
-#define __NR_getresgid          171
-#endif
 #ifndef __NR_rt_sigaction
-#define __NR_rt_sigreturn       173
 #define __NR_rt_sigaction       174
 #define __NR_rt_sigprocmask     175
-#define __NR_rt_sigpending      176
-#define __NR_rt_sigsuspend      179
-#endif
-#ifndef __NR_pread64
-#define __NR_pread64            180
-#endif
-#ifndef __NR_pwrite64
-#define __NR_pwrite64           181
-#endif
-#ifndef __NR_ugetrlimit
-#define __NR_ugetrlimit         191
 #endif
 #ifndef __NR_stat64
 #define __NR_stat64             195
@@ -748,114 +585,21 @@ struct kernel_io_event {
 #ifndef __NR_fstat64
 #define __NR_fstat64            197
 #endif
-#ifndef __NR_setresuid32
-#define __NR_setresuid32        208
-#define __NR_getresuid32        209
-#define __NR_setresgid32        210
-#define __NR_getresgid32        211
-#endif
-#ifndef __NR_setfsuid32
-#define __NR_setfsuid32         215
-#define __NR_setfsgid32         216
-#endif
 #ifndef __NR_getdents64
 #define __NR_getdents64         220
 #endif
 #ifndef __NR_gettid
 #define __NR_gettid             224
 #endif
-#ifndef __NR_readahead
-#define __NR_readahead          225
-#endif
-#ifndef __NR_setxattr
-#define __NR_setxattr           226
-#endif
-#ifndef __NR_lsetxattr
-#define __NR_lsetxattr          227
-#endif
-#ifndef __NR_getxattr
-#define __NR_getxattr           229
-#endif
-#ifndef __NR_lgetxattr
-#define __NR_lgetxattr          230
-#endif
-#ifndef __NR_listxattr
-#define __NR_listxattr          232
-#endif
-#ifndef __NR_llistxattr
-#define __NR_llistxattr         233
-#endif
-#ifndef __NR_tkill
-#define __NR_tkill              238
-#endif
 #ifndef __NR_futex
 #define __NR_futex              240
 #endif
-#ifndef __NR_sched_setaffinity
-#define __NR_sched_setaffinity  241
-#define __NR_sched_getaffinity  242
-#endif
-#ifndef __NR_io_setup
-#define __NR_io_setup           245
-#define __NR_io_destroy         246
-#define __NR_io_getevents       247
-#define __NR_io_submit          248
-#define __NR_io_cancel          249
-#endif
-#ifndef __NR_set_tid_address
-#define __NR_set_tid_address    258
-#endif
-#ifndef __NR_clock_gettime
-#define __NR_clock_gettime      265
-#endif
-#ifndef __NR_clock_getres
-#define __NR_clock_getres       266
-#endif
-#ifndef __NR_statfs64
-#define __NR_statfs64           268
-#endif
-#ifndef __NR_fstatfs64
-#define __NR_fstatfs64          269
-#endif
-#ifndef __NR_fadvise64_64
-#define __NR_fadvise64_64       272
-#endif
-#ifndef __NR_ioprio_set
-#define __NR_ioprio_set         289
-#endif
-#ifndef __NR_ioprio_get
-#define __NR_ioprio_get         290
-#endif
 #ifndef __NR_openat
 #define __NR_openat             295
 #endif
-#ifndef __NR_fstatat64
-#define __NR_fstatat64          300
-#endif
-#ifndef __NR_unlinkat
-#define __NR_unlinkat           301
-#endif
-#ifndef __NR_unshare
-#define __NR_unshare            310
-#endif
-#ifndef __NR_move_pages
-#define __NR_move_pages         317
-#endif
 #ifndef __NR_getcpu
 #define __NR_getcpu             318
 #endif
-#ifndef __NR_fallocate
-#define __NR_fallocate          324
-#endif
-#ifndef __NR_preadv
-#define __NR_preadv             333
-#endif
-#ifndef __NR_pwritev
-#define __NR_pwritev            334
-#endif
-#ifndef __NR_setns
-#define __NR_setns              346
-#endif
 /* End of i386 definitions                                                   */
 #elif defined(__arm__)
 #ifndef __syscall
@@ -875,33 +619,9 @@ struct kernel_io_event {
 #define __syscall_safe(name) __syscall(name)
 #endif
 #endif
-#ifndef __NR_mount
-#define __NR_mount              (__NR_SYSCALL_BASE + 21)
-#endif
-#ifndef __NR_setresuid
-#define __NR_setresuid          (__NR_SYSCALL_BASE + 164)
-#define __NR_getresuid          (__NR_SYSCALL_BASE + 165)
-#define __NR_setresgid          (__NR_SYSCALL_BASE + 170)
-#define __NR_getresgid          (__NR_SYSCALL_BASE + 171)
-#endif
 #ifndef __NR_rt_sigaction
-#define __NR_rt_sigreturn       (__NR_SYSCALL_BASE + 173)
 #define __NR_rt_sigaction       (__NR_SYSCALL_BASE + 174)
 #define __NR_rt_sigprocmask     (__NR_SYSCALL_BASE + 175)
-#define __NR_rt_sigpending      (__NR_SYSCALL_BASE + 176)
-#define __NR_rt_sigsuspend      (__NR_SYSCALL_BASE + 179)
-#endif
-#ifndef __NR_pread64
-#define __NR_pread64            (__NR_SYSCALL_BASE + 180)
-#endif
-#ifndef __NR_pwrite64
-#define __NR_pwrite64           (__NR_SYSCALL_BASE + 181)
-#endif
-#ifndef __NR_capset
-#define __NR_capset             (__NR_SYSCALL_BASE + 185)
-#endif
-#ifndef __NR_ugetrlimit
-#define __NR_ugetrlimit         (__NR_SYSCALL_BASE + 191)
 #endif
 #ifndef __NR_stat64
 #define __NR_stat64             (__NR_SYSCALL_BASE + 195)
@@ -909,228 +629,41 @@ struct kernel_io_event {
 #ifndef __NR_fstat64
 #define __NR_fstat64            (__NR_SYSCALL_BASE + 197)
 #endif
-#ifndef __NR_setgroups32
-#define __NR_setgroups32        (__NR_SYSCALL_BASE + 206)
-#endif
-#ifndef __NR_setresuid32
-#define __NR_setresuid32        (__NR_SYSCALL_BASE + 208)
-#define __NR_getresuid32        (__NR_SYSCALL_BASE + 209)
-#define __NR_setresgid32        (__NR_SYSCALL_BASE + 210)
-#define __NR_getresgid32        (__NR_SYSCALL_BASE + 211)
-#endif
-#ifndef __NR_setfsuid32
-#define __NR_setfsuid32         (__NR_SYSCALL_BASE + 215)
-#define __NR_setfsgid32         (__NR_SYSCALL_BASE + 216)
-#endif
 #ifndef __NR_getdents64
 #define __NR_getdents64         (__NR_SYSCALL_BASE + 217)
 #endif
 #ifndef __NR_gettid
 #define __NR_gettid             (__NR_SYSCALL_BASE + 224)
 #endif
-#ifndef __NR_readahead
-#define __NR_readahead          (__NR_SYSCALL_BASE + 225)
-#endif
-#ifndef __NR_setxattr
-#define __NR_setxattr           (__NR_SYSCALL_BASE + 226)
+#ifndef __NR_futex
+#define __NR_futex              (__NR_SYSCALL_BASE + 240)
 #endif
-#ifndef __NR_lsetxattr
-#define __NR_lsetxattr          (__NR_SYSCALL_BASE + 227)
+/* End of ARM definitions                                                  */
+#elif defined(__x86_64__)
+#ifndef __NR_gettid
+#define __NR_gettid             186
 #endif
-#ifndef __NR_getxattr
-#define __NR_getxattr           (__NR_SYSCALL_BASE + 229)
+#ifndef __NR_futex
+#define __NR_futex              202
 #endif
-#ifndef __NR_lgetxattr
-#define __NR_lgetxattr          (__NR_SYSCALL_BASE + 230)
+#ifndef __NR_getdents64
+#define __NR_getdents64         217
 #endif
-#ifndef __NR_listxattr
-#define __NR_listxattr          (__NR_SYSCALL_BASE + 232)
+#ifndef __NR_openat
+#define __NR_openat             257
 #endif
-#ifndef __NR_llistxattr
-#define __NR_llistxattr         (__NR_SYSCALL_BASE + 233)
+/* End of x86-64 definitions                                                 */
+#elif defined(__mips__)
+#if _MIPS_SIM == _MIPS_SIM_ABI32
+#ifndef __NR_rt_sigaction
+#define __NR_rt_sigaction       (__NR_Linux + 194)
+#define __NR_rt_sigprocmask     (__NR_Linux + 195)
 #endif
-#ifndef __NR_tkill
-#define __NR_tkill              (__NR_SYSCALL_BASE + 238)
+#ifndef __NR_stat64
+#define __NR_stat64             (__NR_Linux + 213)
 #endif
-#ifndef __NR_futex
-#define __NR_futex              (__NR_SYSCALL_BASE + 240)
-#endif
-#ifndef __NR_sched_setaffinity
-#define __NR_sched_setaffinity  (__NR_SYSCALL_BASE + 241)
-#define __NR_sched_getaffinity  (__NR_SYSCALL_BASE + 242)
-#endif
-#ifndef __NR_set_tid_address
-#define __NR_set_tid_address    (__NR_SYSCALL_BASE + 256)
-#endif
-#ifndef __NR_clock_gettime
-#define __NR_clock_gettime      (__NR_SYSCALL_BASE + 263)
-#endif
-#ifndef __NR_clock_getres
-#define __NR_clock_getres       (__NR_SYSCALL_BASE + 264)
-#endif
-#ifndef __NR_statfs64
-#define __NR_statfs64           (__NR_SYSCALL_BASE + 266)
-#endif
-#ifndef __NR_fstatfs64
-#define __NR_fstatfs64          (__NR_SYSCALL_BASE + 267)
-#endif
-#ifndef __NR_ioprio_set
-#define __NR_ioprio_set         (__NR_SYSCALL_BASE + 314)
-#endif
-#ifndef __NR_ioprio_get
-#define __NR_ioprio_get         (__NR_SYSCALL_BASE + 315)
-#endif
-#ifndef __NR_unshare
-#define __NR_unshare            (__NR_SYSCALL_BASE + 337)
-#endif
-#ifndef __NR_move_pages
-#define __NR_move_pages         (__NR_SYSCALL_BASE + 344)
-#endif
-#ifndef __NR_setns
-#define __NR_setns              (__NR_SYSCALL_BASE + 375)
-#endif
-/* End of ARM definitions                                                  */
-#elif defined(__x86_64__)
-#ifndef __NR_pread64
-#define __NR_pread64             17
-#endif
-#ifndef __NR_pwrite64
-#define __NR_pwrite64            18
-#endif
-#ifndef __NR_setresuid
-#define __NR_setresuid          117
-#define __NR_getresuid          118
-#define __NR_setresgid          119
-#define __NR_getresgid          120
-#endif
-#ifndef __NR_mount
-#define __NR_mount              165
-#endif
-#ifndef __NR_quotactl
-#define __NR_quotactl           179
-#endif
-#ifndef __NR_gettid
-#define __NR_gettid             186
-#endif
-#ifndef __NR_readahead
-#define __NR_readahead          187
-#endif
-#ifndef __NR_setxattr
-#define __NR_setxattr           188
-#endif
-#ifndef __NR_lsetxattr
-#define __NR_lsetxattr          189
-#endif
-#ifndef __NR_getxattr
-#define __NR_getxattr           191
-#endif
-#ifndef __NR_lgetxattr
-#define __NR_lgetxattr          192
-#endif
-#ifndef __NR_listxattr
-#define __NR_listxattr          194
-#endif
-#ifndef __NR_llistxattr
-#define __NR_llistxattr         195
-#endif
-#ifndef __NR_tkill
-#define __NR_tkill              200
-#endif
-#ifndef __NR_futex
-#define __NR_futex              202
-#endif
-#ifndef __NR_sched_setaffinity
-#define __NR_sched_setaffinity  203
-#define __NR_sched_getaffinity  204
-#endif
-#ifndef __NR_io_setup
-#define __NR_io_setup           206
-#define __NR_io_destroy         207
-#define __NR_io_getevents       208
-#define __NR_io_submit          209
-#define __NR_io_cancel          210
-#endif
-#ifndef __NR_getdents64
-#define __NR_getdents64         217
-#endif
-#ifndef __NR_set_tid_address
-#define __NR_set_tid_address    218
-#endif
-#ifndef __NR_fadvise64
-#define __NR_fadvise64          221
-#endif
-#ifndef __NR_clock_gettime
-#define __NR_clock_gettime      228
-#endif
-#ifndef __NR_clock_getres
-#define __NR_clock_getres       229
-#endif
-#ifndef __NR_ioprio_set
-#define __NR_ioprio_set         251
-#endif
-#ifndef __NR_ioprio_get
-#define __NR_ioprio_get         252
-#endif
-#ifndef __NR_openat
-#define __NR_openat             257
-#endif
-#ifndef __NR_newfstatat
-#define __NR_newfstatat         262
-#endif
-#ifndef __NR_unlinkat
-#define __NR_unlinkat           263
-#endif
-#ifndef __NR_unshare
-#define __NR_unshare            272
-#endif
-#ifndef __NR_move_pages
-#define __NR_move_pages         279
-#endif
-#ifndef __NR_fallocate
-#define __NR_fallocate          285
-#endif
-#ifndef __NR_preadv
-#define __NR_preadv             295
-#endif
-#ifndef __NR_pwritev
-#define __NR_pwritev            296
-#endif
-#ifndef __NR_setns
-#define __NR_setns              308
-#endif
-/* End of x86-64 definitions                                                 */
-#elif defined(__mips__)
-#if _MIPS_SIM == _MIPS_SIM_ABI32
-#ifndef __NR_mount
-#define __NR_mount              (__NR_Linux + 21)
-#endif
-#ifndef __NR_setresuid
-#define __NR_setresuid          (__NR_Linux + 185)
-#define __NR_getresuid          (__NR_Linux + 186)
-#define __NR_setresgid          (__NR_Linux + 190)
-#define __NR_getresgid          (__NR_Linux + 191)
-#endif
-#ifndef __NR_rt_sigaction
-#define __NR_rt_sigreturn       (__NR_Linux + 193)
-#define __NR_rt_sigaction       (__NR_Linux + 194)
-#define __NR_rt_sigprocmask     (__NR_Linux + 195)
-#define __NR_rt_sigpending      (__NR_Linux + 196)
-#define __NR_rt_sigsuspend      (__NR_Linux + 199)
-#endif
-#ifndef __NR_pread64
-#define __NR_pread64            (__NR_Linux + 200)
-#endif
-#ifndef __NR_pwrite64
-#define __NR_pwrite64           (__NR_Linux + 201)
-#endif
-#ifndef __NR_capset
-#define __NR_capset             (__NR_Linux + 205)
-#endif
-#ifndef __NR_stat64
-#define __NR_stat64             (__NR_Linux + 213)
-#endif
-#ifndef __NR_fstat64
-#define __NR_fstat64            (__NR_Linux + 215)
+#ifndef __NR_fstat64
+#define __NR_fstat64            (__NR_Linux + 215)
 #endif
 #ifndef __NR_getdents64
 #define __NR_getdents64         (__NR_Linux + 219)
@@ -1138,390 +671,273 @@ struct kernel_io_event {
 #ifndef __NR_gettid
 #define __NR_gettid             (__NR_Linux + 222)
 #endif
-#ifndef __NR_readahead
-#define __NR_readahead          (__NR_Linux + 223)
-#endif
-#ifndef __NR_setxattr
-#define __NR_setxattr           (__NR_Linux + 224)
-#endif
-#ifndef __NR_lsetxattr
-#define __NR_lsetxattr          (__NR_Linux + 225)
-#endif
-#ifndef __NR_getxattr
-#define __NR_getxattr           (__NR_Linux + 227)
-#endif
-#ifndef __NR_lgetxattr
-#define __NR_lgetxattr          (__NR_Linux + 228)
-#endif
-#ifndef __NR_listxattr
-#define __NR_listxattr          (__NR_Linux + 230)
-#endif
-#ifndef __NR_llistxattr
-#define __NR_llistxattr         (__NR_Linux + 231)
-#endif
-#ifndef __NR_tkill
-#define __NR_tkill              (__NR_Linux + 236)
-#endif
 #ifndef __NR_futex
 #define __NR_futex              (__NR_Linux + 238)
 #endif
-#ifndef __NR_sched_setaffinity
-#define __NR_sched_setaffinity  (__NR_Linux + 239)
-#define __NR_sched_getaffinity  (__NR_Linux + 240)
-#endif
-#ifndef __NR_set_tid_address
-#define __NR_set_tid_address    (__NR_Linux + 252)
-#endif
-#ifndef __NR_statfs64
-#define __NR_statfs64           (__NR_Linux + 255)
-#endif
-#ifndef __NR_fstatfs64
-#define __NR_fstatfs64          (__NR_Linux + 256)
-#endif
-#ifndef __NR_clock_gettime
-#define __NR_clock_gettime      (__NR_Linux + 263)
-#endif
-#ifndef __NR_clock_getres
-#define __NR_clock_getres       (__NR_Linux + 264)
-#endif
 #ifndef __NR_openat
 #define __NR_openat             (__NR_Linux + 288)
 #endif
 #ifndef __NR_fstatat
 #define __NR_fstatat            (__NR_Linux + 293)
 #endif
-#ifndef __NR_unlinkat
-#define __NR_unlinkat           (__NR_Linux + 294)
-#endif
-#ifndef __NR_unshare
-#define __NR_unshare            (__NR_Linux + 303)
-#endif
-#ifndef __NR_move_pages
-#define __NR_move_pages         (__NR_Linux + 308)
-#endif
 #ifndef __NR_getcpu
 #define __NR_getcpu             (__NR_Linux + 312)
 #endif
-#ifndef __NR_ioprio_set
-#define __NR_ioprio_set         (__NR_Linux + 314)
-#endif
-#ifndef __NR_ioprio_get
-#define __NR_ioprio_get         (__NR_Linux + 315)
-#endif
-#ifndef __NR_setns
-#define __NR_setns              (__NR_Linux + 344)
-#endif
 /* End of MIPS (old 32bit API) definitions */
-#elif  _MIPS_SIM == _MIPS_SIM_ABI64
-#ifndef __NR_pread64
-#define __NR_pread64            (__NR_Linux +  16)
-#endif
-#ifndef __NR_pwrite64
-#define __NR_pwrite64           (__NR_Linux +  17)
-#endif
-#ifndef __NR_setresuid
-#define __NR_setresuid          (__NR_Linux + 115)
-#define __NR_getresuid          (__NR_Linux + 116)
-#define __NR_setresgid          (__NR_Linux + 117)
-#define __NR_getresgid          (__NR_Linux + 118)
-#endif
-#ifndef __NR_capset
-#define __NR_capset             (__NR_Linux + 124)
-#endif
-#ifndef __NR_mount
-#define __NR_mount              (__NR_Linux + 160)
-#endif
+#elif (_MIPS_SIM == _MIPS_SIM_ABI64 || _MIPS_SIM == _MIPS_SIM_NABI32)
 #ifndef __NR_gettid
 #define __NR_gettid             (__NR_Linux + 178)
 #endif
-#ifndef __NR_readahead
-#define __NR_readahead          (__NR_Linux + 179)
-#endif
-#ifndef __NR_setxattr
-#define __NR_setxattr           (__NR_Linux + 180)
-#endif
-#ifndef __NR_lsetxattr
-#define __NR_lsetxattr          (__NR_Linux + 181)
-#endif
-#ifndef __NR_getxattr
-#define __NR_getxattr           (__NR_Linux + 183)
-#endif
-#ifndef __NR_lgetxattr
-#define __NR_lgetxattr          (__NR_Linux + 184)
-#endif
-#ifndef __NR_listxattr
-#define __NR_listxattr          (__NR_Linux + 186)
-#endif
-#ifndef __NR_llistxattr
-#define __NR_llistxattr         (__NR_Linux + 187)
-#endif
-#ifndef __NR_tkill
-#define __NR_tkill              (__NR_Linux + 192)
-#endif
 #ifndef __NR_futex
 #define __NR_futex              (__NR_Linux + 194)
 #endif
-#ifndef __NR_sched_setaffinity
-#define __NR_sched_setaffinity  (__NR_Linux + 195)
-#define __NR_sched_getaffinity  (__NR_Linux + 196)
-#endif
-#ifndef __NR_set_tid_address
-#define __NR_set_tid_address    (__NR_Linux + 212)
-#endif
-#ifndef __NR_clock_gettime
-#define __NR_clock_gettime      (__NR_Linux + 222)
-#endif
-#ifndef __NR_clock_getres
-#define __NR_clock_getres       (__NR_Linux + 223)
-#endif
 #ifndef __NR_openat
 #define __NR_openat             (__NR_Linux + 247)
 #endif
 #ifndef __NR_fstatat
 #define __NR_fstatat            (__NR_Linux + 252)
 #endif
-#ifndef __NR_unlinkat
-#define __NR_unlinkat           (__NR_Linux + 253)
-#endif
-#ifndef __NR_unshare
-#define __NR_unshare            (__NR_Linux + 262)
-#endif
-#ifndef __NR_move_pages
-#define __NR_move_pages         (__NR_Linux + 267)
-#endif
 #ifndef __NR_getcpu
 #define __NR_getcpu             (__NR_Linux + 271)
 #endif
-#ifndef __NR_ioprio_set
-#define __NR_ioprio_set         (__NR_Linux + 273)
-#endif
-#ifndef __NR_ioprio_get
-#define __NR_ioprio_get         (__NR_Linux + 274)
-#endif
-#ifndef __NR_setns
-#define __NR_setns              (__NR_Linux + 303)
-#endif
 /* End of MIPS (64bit API) definitions */
 #else
-#ifndef __NR_mount
-#define __NR_mount              (__NR_Linux + 160)
-#endif
-#ifndef __NR_setresuid
-#define __NR_setresuid          (__NR_Linux + 115)
-#define __NR_getresuid          (__NR_Linux + 116)
-#define __NR_setresgid          (__NR_Linux + 117)
-#define __NR_getresgid          (__NR_Linux + 118)
-#endif
-#ifndef __NR_capset
-#define __NR_capset             (__NR_Linux + 124)
-#endif
 #ifndef __NR_gettid
 #define __NR_gettid             (__NR_Linux + 178)
 #endif
-#ifndef __NR_readahead
-#define __NR_readahead          (__NR_Linux + 179)
-#endif
-#ifndef __NR_setxattr
-#define __NR_setxattr           (__NR_Linux + 180)
-#endif
-#ifndef __NR_lsetxattr
-#define __NR_lsetxattr          (__NR_Linux + 181)
-#endif
-#ifndef __NR_getxattr
-#define __NR_getxattr           (__NR_Linux + 183)
-#endif
-#ifndef __NR_lgetxattr
-#define __NR_lgetxattr          (__NR_Linux + 184)
-#endif
-#ifndef __NR_listxattr
-#define __NR_listxattr          (__NR_Linux + 186)
-#endif
-#ifndef __NR_llistxattr
-#define __NR_llistxattr         (__NR_Linux + 187)
-#endif
-#ifndef __NR_tkill
-#define __NR_tkill              (__NR_Linux + 192)
-#endif
 #ifndef __NR_futex
 #define __NR_futex              (__NR_Linux + 194)
 #endif
-#ifndef __NR_sched_setaffinity
-#define __NR_sched_setaffinity  (__NR_Linux + 195)
-#define __NR_sched_getaffinity  (__NR_Linux + 196)
-#endif
-#ifndef __NR_set_tid_address
-#define __NR_set_tid_address    (__NR_Linux + 213)
-#endif
-#ifndef __NR_statfs64
-#define __NR_statfs64           (__NR_Linux + 217)
-#endif
-#ifndef __NR_fstatfs64
-#define __NR_fstatfs64          (__NR_Linux + 218)
-#endif
-#ifndef __NR_clock_gettime
-#define __NR_clock_gettime      (__NR_Linux + 226)
-#endif
-#ifndef __NR_clock_getres
-#define __NR_clock_getres       (__NR_Linux + 227)
-#endif
 #ifndef __NR_openat
 #define __NR_openat             (__NR_Linux + 251)
 #endif
 #ifndef __NR_fstatat
 #define __NR_fstatat            (__NR_Linux + 256)
 #endif
-#ifndef __NR_unlinkat
-#define __NR_unlinkat           (__NR_Linux + 257)
-#endif
-#ifndef __NR_unshare
-#define __NR_unshare            (__NR_Linux + 266)
-#endif
-#ifndef __NR_move_pages
-#define __NR_move_pages         (__NR_Linux + 271)
-#endif
 #ifndef __NR_getcpu
 #define __NR_getcpu             (__NR_Linux + 275)
 #endif
-#ifndef __NR_ioprio_set
-#define __NR_ioprio_set         (__NR_Linux + 277)
-#endif
-#ifndef __NR_ioprio_get
-#define __NR_ioprio_get         (__NR_Linux + 278)
-#endif
-#ifndef __NR_setns
-#define __NR_setns              (__NR_Linux + 308)
-#endif
 /* End of MIPS (new 32bit API) definitions                                   */
 #endif
 /* End of MIPS definitions                                                   */
 #elif defined(__PPC__)
-#ifndef __NR_mount
-#define __NR_mount              21
-#endif
-#ifndef __NR_setfsuid
-#define __NR_setfsuid           138
-#define __NR_setfsgid           139
-#endif
-#ifndef __NR_setresuid
-#define __NR_setresuid          164
-#define __NR_getresuid          165
-#define __NR_setresgid          169
-#define __NR_getresgid          170
-#endif
 #ifndef __NR_rt_sigaction
-#define __NR_rt_sigreturn       172
 #define __NR_rt_sigaction       173
 #define __NR_rt_sigprocmask     174
-#define __NR_rt_sigpending      175
-#define __NR_rt_sigsuspend      178
-#endif
-#ifndef __NR_pread64
-#define __NR_pread64            179
-#endif
-#ifndef __NR_pwrite64
-#define __NR_pwrite64           180
-#endif
-#ifndef __NR_capset
-#define __NR_capset             184
 #endif
-#ifndef __NR_ugetrlimit
-#define __NR_ugetrlimit         190
-#endif
-#ifndef __NR_readahead
-#define __NR_readahead          191
-#endif
-#ifndef __PPC64__
 #ifndef __NR_stat64
 #define __NR_stat64             195
 #endif
 #ifndef __NR_fstat64
 #define __NR_fstat64            197
 #endif
-#endif /* !defined(__PPC64__) */
+#ifndef __NR_socket
+#define __NR_socket             198
+#endif
 #ifndef __NR_getdents64
 #define __NR_getdents64         202
 #endif
 #ifndef __NR_gettid
 #define __NR_gettid             207
 #endif
-#ifndef __NR_tkill
-#define __NR_tkill              208
+#ifndef __NR_futex
+#define __NR_futex              221
+#endif
+#ifndef __NR_openat
+#define __NR_openat             286
+#endif
+#ifndef __NR_getcpu
+#define __NR_getcpu             302
+#endif
+/* End of powerpc defininitions                                              */
+#elif defined(__aarch64__)
+#ifndef __NR_fstatat
+#define __NR_fstatat             79
+#endif
+/* End of aarch64 defininitions                                              */
+#elif defined(__s390__)
+#ifndef __NR_quotactl
+#define __NR_quotactl           131
+#endif
+#ifndef __NR_rt_sigreturn
+#define __NR_rt_sigreturn       173
+#endif
+#ifndef __NR_rt_sigaction
+#define __NR_rt_sigaction       174
+#endif
+#ifndef __NR_rt_sigprocmask
+#define __NR_rt_sigprocmask     175
+#endif
+#ifndef __NR_rt_sigpending
+#define __NR_rt_sigpending      176
+#endif
+#ifndef __NR_rt_sigsuspend
+#define __NR_rt_sigsuspend      179
+#endif
+#ifndef __NR_pread64
+#define __NR_pread64            180
+#endif
+#ifndef __NR_pwrite64
+#define __NR_pwrite64           181
+#endif
+#ifndef __NR_getdents64
+#define __NR_getdents64         220
+#endif
+#ifndef __NR_readahead
+#define __NR_readahead          222
 #endif
 #ifndef __NR_setxattr
-#define __NR_setxattr           209
+#define __NR_setxattr           224
 #endif
 #ifndef __NR_lsetxattr
-#define __NR_lsetxattr          210
+#define __NR_lsetxattr          225
 #endif
 #ifndef __NR_getxattr
-#define __NR_getxattr           212
+#define __NR_getxattr           227
 #endif
 #ifndef __NR_lgetxattr
-#define __NR_lgetxattr          213
+#define __NR_lgetxattr          228
 #endif
 #ifndef __NR_listxattr
-#define __NR_listxattr          215
+#define __NR_listxattr          230
 #endif
 #ifndef __NR_llistxattr
-#define __NR_llistxattr         216
+#define __NR_llistxattr         231
+#endif
+#ifndef __NR_gettid
+#define __NR_gettid             236
+#endif
+#ifndef __NR_tkill
+#define __NR_tkill              237
 #endif
 #ifndef __NR_futex
-#define __NR_futex              221
+#define __NR_futex              238
 #endif
 #ifndef __NR_sched_setaffinity
-#define __NR_sched_setaffinity  222
-#define __NR_sched_getaffinity  223
+#define __NR_sched_setaffinity  239
+#endif
+#ifndef __NR_sched_getaffinity
+#define __NR_sched_getaffinity  240
 #endif
 #ifndef __NR_set_tid_address
-#define __NR_set_tid_address    232
+#define __NR_set_tid_address    252
 #endif
 #ifndef __NR_clock_gettime
-#define __NR_clock_gettime      246
+#define __NR_clock_gettime      260
 #endif
 #ifndef __NR_clock_getres
-#define __NR_clock_getres       247
+#define __NR_clock_getres       261
 #endif
 #ifndef __NR_statfs64
-#define __NR_statfs64           252
+#define __NR_statfs64           265
 #endif
 #ifndef __NR_fstatfs64
-#define __NR_fstatfs64          253
-#endif
-#ifndef __PPC64__
-#ifndef __NR_fadvise64_64
-#define __NR_fadvise64_64       254
+#define __NR_fstatfs64          266
 #endif
-#endif /* !defined(__PPC64__) */
 #ifndef __NR_ioprio_set
-#define __NR_ioprio_set         273
+#define __NR_ioprio_set         282
 #endif
 #ifndef __NR_ioprio_get
-#define __NR_ioprio_get         274
-#endif
-#ifndef __NR_unshare
-#define __NR_unshare            282
+#define __NR_ioprio_get         283
 #endif
 #ifndef __NR_openat
-#define __NR_openat             286
-#endif
-#ifndef __PPC64__
-#ifndef __NR_fstatat64
-#define __NR_fstatat64          291
+#define __NR_openat             288
 #endif
-#endif /* !defined(__PPC64__) */
 #ifndef __NR_unlinkat
-#define __NR_unlinkat           292
+#define __NR_unlinkat           294
 #endif
 #ifndef __NR_move_pages
-#define __NR_move_pages         301
+#define __NR_move_pages         310
 #endif
 #ifndef __NR_getcpu
-#define __NR_getcpu             302
-#endif
-#ifndef __NR_setns
-#define __NR_setns              350
+#define __NR_getcpu             311
 #endif
-/* End of powerpc defininitions                                              */
+#ifndef __NR_fallocate
+#define __NR_fallocate          314
+#endif
+/* Some syscalls are named/numbered differently between s390 and s390x. */
+#ifdef __s390x__
+# ifndef __NR_getrlimit
+# define __NR_getrlimit          191
+# endif
+# ifndef __NR_setresuid
+# define __NR_setresuid          208
+# endif
+# ifndef __NR_getresuid
+# define __NR_getresuid          209
+# endif
+# ifndef __NR_setresgid
+# define __NR_setresgid          210
+# endif
+# ifndef __NR_getresgid
+# define __NR_getresgid          211
+# endif
+# ifndef __NR_setfsuid
+# define __NR_setfsuid           215
+# endif
+# ifndef __NR_setfsgid
+# define __NR_setfsgid           216
+# endif
+# ifndef __NR_fadvise64
+# define __NR_fadvise64          253
+# endif
+# ifndef __NR_newfstatat
+# define __NR_newfstatat         293
+# endif
+#else /* __s390x__ */
+# ifndef __NR_getrlimit
+# define __NR_getrlimit          76
+# endif
+# ifndef __NR_setfsuid
+# define __NR_setfsuid           138
+# endif
+# ifndef __NR_setfsgid
+# define __NR_setfsgid           139
+# endif
+# ifndef __NR_setresuid
+# define __NR_setresuid          164
+# endif
+# ifndef __NR_getresuid
+# define __NR_getresuid          165
+# endif
+# ifndef __NR_setresgid
+# define __NR_setresgid          170
+# endif
+# ifndef __NR_getresgid
+# define __NR_getresgid          171
+# endif
+# ifndef __NR_ugetrlimit
+# define __NR_ugetrlimit         191
+# endif
+# ifndef __NR_mmap2
+# define __NR_mmap2              192
+# endif
+# ifndef __NR_setresuid32
+# define __NR_setresuid32        208
+# endif
+# ifndef __NR_getresuid32
+# define __NR_getresuid32        209
+# endif
+# ifndef __NR_setresgid32
+# define __NR_setresgid32        210
+# endif
+# ifndef __NR_getresgid32
+# define __NR_getresgid32        211
+# endif
+# ifndef __NR_setfsuid32
+# define __NR_setfsuid32         215
+# endif
+# ifndef __NR_setfsgid32
+# define __NR_setfsgid32         216
+# endif
+# ifndef __NR_fadvise64_64
+# define __NR_fadvise64_64       264
+# endif
+# ifndef __NR_fstatat64
+# define __NR_fstatat64          293
+# endif
+#endif /* __s390__ */
+/* End of s390/s390x definitions                                             */
 #endif


@@ -1584,7 +1000,8 @@ struct kernel_io_event {
   #endif

   #undef  LSS_RETURN
-  #if (defined(__i386__) || defined(__x86_64__) || defined(__arm__))
+  #if (defined(__i386__) || defined(__x86_64__) || defined(__arm__) ||        \
+       defined(__aarch64__) || defined(__s390__))
   /* Failing system calls return a negative result in the range of
    * -1..-4095. These are "errno" values with the sign inverted.
    */
@@ -1818,35 +1235,6 @@ struct kernel_io_event {
       LSS_RETURN(int, __res);
     }

-    #define __NR__fadvise64_64 __NR_fadvise64_64
-    LSS_INLINE _syscall6(int, _fadvise64_64, int, fd,
-                         unsigned, offset_lo, unsigned, offset_hi,
-                         unsigned, len_lo, unsigned, len_hi,
-                         int, advice)
-
-    LSS_INLINE int LSS_NAME(fadvise64)(int fd, loff_t offset,
-                                       loff_t len, int advice) {
-      return LSS_NAME(_fadvise64_64)(fd,
-                                     (unsigned)offset, (unsigned)(offset >>32),
-                                     (unsigned)len, (unsigned)(len >> 32),
-                                     advice);
-    }
-
-    #define __NR__fallocate __NR_fallocate
-    LSS_INLINE _syscall6(int, _fallocate, int, fd,
-                         int, mode,
-                         unsigned, offset_lo, unsigned, offset_hi,
-                         unsigned, len_lo, unsigned, len_hi)
-
-    LSS_INLINE int LSS_NAME(fallocate)(int fd, int mode,
-                                       loff_t offset, loff_t len) {
-      union { loff_t off; unsigned w[2]; } o = { offset }, l = { len };
-      return LSS_NAME(_fallocate)(fd, mode, o.w[0], o.w[1], l.w[0], l.w[1]);
-    }
-
-    LSS_INLINE _syscall1(int, set_thread_area, void *, u)
-    LSS_INLINE _syscall1(int, get_thread_area, void *, u)
-
     LSS_INLINE void (*LSS_NAME(restore_rt)(void))(void) {
       /* On i386, the kernel does not know how to return from a signal
        * handler. Instead, it relies on user space to provide a
@@ -1891,74 +1279,141 @@ struct kernel_io_event {
      * location (e.g. when using the clone() system call with the CLONE_VM
      * option).
      */
+    #undef  LSS_ENTRYPOINT
+    #define LSS_ENTRYPOINT "syscall\n"
+
+    /* The x32 ABI has 32 bit longs, but the syscall interface is 64 bit.
+     * We need to explicitly cast to an unsigned 64 bit type to avoid implicit
+     * sign extension.  We can't cast pointers directly because those are
+     * 32 bits, and gcc will dump ugly warnings about casting from a pointer
+     * to an integer of a different size.
+     */
+    #undef  LSS_SYSCALL_ARG
+    #define LSS_SYSCALL_ARG(a) ((uint64_t)(uintptr_t)(a))
+    #undef  _LSS_RETURN
+    #define _LSS_RETURN(type, res, cast)                                      \
+      do {                                                                    \
+        if ((uint64_t)(res) >= (uint64_t)(-4095)) {                           \
+          LSS_ERRNO = -(res);                                                 \
+          res = -1;                                                           \
+        }                                                                     \
+        return (type)(cast)(res);                                             \
+      } while (0)
+    #undef  LSS_RETURN
+    #define LSS_RETURN(type, res) _LSS_RETURN(type, res, uintptr_t)
+
+    #undef  _LSS_BODY
+    #define _LSS_BODY(nr, type, name, cast, ...)                              \
+          long long __res;                                                    \
+          __asm__ __volatile__(LSS_BODY_ASM##nr LSS_ENTRYPOINT                \
+            : "=a" (__res)                                                    \
+            : "0" (__NR_##name) LSS_BODY_ARG##nr(__VA_ARGS__)                 \
+            : LSS_BODY_CLOBBER##nr "r11", "rcx", "memory");                   \
+          _LSS_RETURN(type, __res, cast)
     #undef  LSS_BODY
-    #define LSS_BODY(type,name, ...)                                          \
-          long __res;                                                         \
-          __asm__ __volatile__("syscall" : "=a" (__res) : "0" (__NR_##name),  \
-            ##__VA_ARGS__ : "r11", "rcx", "memory");                          \
-          LSS_RETURN(type, __res)
+    #define LSS_BODY(nr, type, name, args...) \
+      _LSS_BODY(nr, type, name, uintptr_t, ## args)
+
+    #undef  LSS_BODY_ASM0
+    #undef  LSS_BODY_ASM1
+    #undef  LSS_BODY_ASM2
+    #undef  LSS_BODY_ASM3
+    #undef  LSS_BODY_ASM4
+    #undef  LSS_BODY_ASM5
+    #undef  LSS_BODY_ASM6
+    #define LSS_BODY_ASM0
+    #define LSS_BODY_ASM1 LSS_BODY_ASM0
+    #define LSS_BODY_ASM2 LSS_BODY_ASM1
+    #define LSS_BODY_ASM3 LSS_BODY_ASM2
+    #define LSS_BODY_ASM4 LSS_BODY_ASM3 "movq %5,%%r10;"
+    #define LSS_BODY_ASM5 LSS_BODY_ASM4 "movq %6,%%r8;"
+    #define LSS_BODY_ASM6 LSS_BODY_ASM5 "movq %7,%%r9;"
+
+    #undef  LSS_BODY_CLOBBER0
+    #undef  LSS_BODY_CLOBBER1
+    #undef  LSS_BODY_CLOBBER2
+    #undef  LSS_BODY_CLOBBER3
+    #undef  LSS_BODY_CLOBBER4
+    #undef  LSS_BODY_CLOBBER5
+    #undef  LSS_BODY_CLOBBER6
+    #define LSS_BODY_CLOBBER0
+    #define LSS_BODY_CLOBBER1 LSS_BODY_CLOBBER0
+    #define LSS_BODY_CLOBBER2 LSS_BODY_CLOBBER1
+    #define LSS_BODY_CLOBBER3 LSS_BODY_CLOBBER2
+    #define LSS_BODY_CLOBBER4 LSS_BODY_CLOBBER3 "r10",
+    #define LSS_BODY_CLOBBER5 LSS_BODY_CLOBBER4 "r8",
+    #define LSS_BODY_CLOBBER6 LSS_BODY_CLOBBER5 "r9",
+
+    #undef  LSS_BODY_ARG0
+    #undef  LSS_BODY_ARG1
+    #undef  LSS_BODY_ARG2
+    #undef  LSS_BODY_ARG3
+    #undef  LSS_BODY_ARG4
+    #undef  LSS_BODY_ARG5
+    #undef  LSS_BODY_ARG6
+    #define LSS_BODY_ARG0()
+    #define LSS_BODY_ARG1(arg1) \
+      LSS_BODY_ARG0(), "D" (arg1)
+    #define LSS_BODY_ARG2(arg1, arg2) \
+      LSS_BODY_ARG1(arg1), "S" (arg2)
+    #define LSS_BODY_ARG3(arg1, arg2, arg3) \
+      LSS_BODY_ARG2(arg1, arg2), "d" (arg3)
+    #define LSS_BODY_ARG4(arg1, arg2, arg3, arg4) \
+      LSS_BODY_ARG3(arg1, arg2, arg3), "r" (arg4)
+    #define LSS_BODY_ARG5(arg1, arg2, arg3, arg4, arg5) \
+      LSS_BODY_ARG4(arg1, arg2, arg3, arg4), "r" (arg5)
+    #define LSS_BODY_ARG6(arg1, arg2, arg3, arg4, arg5, arg6) \
+      LSS_BODY_ARG5(arg1, arg2, arg3, arg4, arg5), "r" (arg6)
+
     #undef _syscall0
     #define _syscall0(type,name)                                              \
       type LSS_NAME(name)() {                                                 \
-        LSS_BODY(type, name);                                                 \
+        LSS_BODY(0, type, name);                                              \
       }
     #undef _syscall1
     #define _syscall1(type,name,type1,arg1)                                   \
       type LSS_NAME(name)(type1 arg1) {                                       \
-        LSS_BODY(type, name, "D" ((long)(arg1)));                             \
+        LSS_BODY(1, type, name, LSS_SYSCALL_ARG(arg1));                       \
       }
     #undef _syscall2
     #define _syscall2(type,name,type1,arg1,type2,arg2)                        \
       type LSS_NAME(name)(type1 arg1, type2 arg2) {                           \
-        LSS_BODY(type, name, "D" ((long)(arg1)), "S" ((long)(arg2)));         \
+        LSS_BODY(2, type, name, LSS_SYSCALL_ARG(arg1), LSS_SYSCALL_ARG(arg2));\
       }
     #undef _syscall3
     #define _syscall3(type,name,type1,arg1,type2,arg2,type3,arg3)             \
       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3) {               \
-        LSS_BODY(type, name, "D" ((long)(arg1)), "S" ((long)(arg2)),          \
-                             "d" ((long)(arg3)));                             \
+        LSS_BODY(3, type, name, LSS_SYSCALL_ARG(arg1), LSS_SYSCALL_ARG(arg2), \
+                                LSS_SYSCALL_ARG(arg3));                       \
       }
     #undef _syscall4
     #define _syscall4(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4)  \
       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3, type4 arg4) {   \
-          long __res;                                                         \
-          __asm__ __volatile__("movq %5,%%r10; syscall" :                     \
-            "=a" (__res) : "0" (__NR_##name),                                 \
-            "D" ((long)(arg1)), "S" ((long)(arg2)), "d" ((long)(arg3)),       \
-            "r" ((long)(arg4)) : "r10", "r11", "rcx", "memory");              \
-          LSS_RETURN(type, __res);                                            \
+        LSS_BODY(4, type, name, LSS_SYSCALL_ARG(arg1), LSS_SYSCALL_ARG(arg2), \
+                                LSS_SYSCALL_ARG(arg3), LSS_SYSCALL_ARG(arg4));\
       }
     #undef _syscall5
     #define _syscall5(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,  \
                       type5,arg5)                                             \
       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3, type4 arg4,     \
                           type5 arg5) {                                       \
-          long __res;                                                         \
-          __asm__ __volatile__("movq %5,%%r10; movq %6,%%r8; syscall" :       \
-            "=a" (__res) : "0" (__NR_##name),                                 \
-            "D" ((long)(arg1)), "S" ((long)(arg2)), "d" ((long)(arg3)),       \
-            "r" ((long)(arg4)), "r" ((long)(arg5)) :                          \
-            "r8", "r10", "r11", "rcx", "memory");                             \
-          LSS_RETURN(type, __res);                                            \
+        LSS_BODY(5, type, name, LSS_SYSCALL_ARG(arg1), LSS_SYSCALL_ARG(arg2), \
+                                LSS_SYSCALL_ARG(arg3), LSS_SYSCALL_ARG(arg4), \
+                                LSS_SYSCALL_ARG(arg5));                       \
       }
     #undef _syscall6
     #define _syscall6(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,  \
                       type5,arg5,type6,arg6)                                  \
       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3, type4 arg4,     \
                           type5 arg5, type6 arg6) {                           \
-          long __res;                                                         \
-          __asm__ __volatile__("movq %5,%%r10; movq %6,%%r8; movq %7,%%r9;"   \
-                               "syscall" :                                    \
-            "=a" (__res) : "0" (__NR_##name),                                 \
-            "D" ((long)(arg1)), "S" ((long)(arg2)), "d" ((long)(arg3)),       \
-            "r" ((long)(arg4)), "r" ((long)(arg5)), "r" ((long)(arg6)) :      \
-            "r8", "r9", "r10", "r11", "rcx", "memory");                       \
-          LSS_RETURN(type, __res);                                            \
+        LSS_BODY(6, type, name, LSS_SYSCALL_ARG(arg1), LSS_SYSCALL_ARG(arg2), \
+                                LSS_SYSCALL_ARG(arg3), LSS_SYSCALL_ARG(arg4), \
+                                LSS_SYSCALL_ARG(arg5), LSS_SYSCALL_ARG(arg6));\
       }
     LSS_INLINE int LSS_NAME(clone)(int (*fn)(void *), void *child_stack,
                                    int flags, void *arg, int *parent_tidptr,
                                    void *newtls, int *child_tidptr) {
-      long __res;
+      long long __res;
       {
         __asm__ __volatile__(/* if (fn == NULL)
                               *   return -EINVAL;
@@ -2023,15 +1478,17 @@ struct kernel_io_event {
                            "1:\n"
                              : "=a" (__res)
                              : "0"(-EINVAL), "i"(__NR_clone), "i"(__NR_exit),
-                               "r"(fn), "S"(child_stack), "D"(flags), "r"(arg),
-                               "d"(parent_tidptr), "g"(newtls), "g"(child_tidptr)
-                             : "rsp", "memory", "r8", "r10", "r11", "rcx");
+                               "r"(LSS_SYSCALL_ARG(fn)),
+                               "S"(LSS_SYSCALL_ARG(child_stack)),
+                               "D"(LSS_SYSCALL_ARG(flags)),
+                               "r"(LSS_SYSCALL_ARG(arg)),
+                               "d"(LSS_SYSCALL_ARG(parent_tidptr)),
+                               "r"(LSS_SYSCALL_ARG(newtls)),
+                               "r"(LSS_SYSCALL_ARG(child_tidptr))
+                             : "memory", "r8", "r10", "r11", "rcx");
       }
       LSS_RETURN(int, __res);
     }
-    LSS_INLINE _syscall2(int, arch_prctl, int, c, void *, a)
-    LSS_INLINE _syscall4(int, fadvise64, int, fd, loff_t, offset, loff_t, len,
-                         int,  advice)

     LSS_INLINE void (*LSS_NAME(restore_rt)(void))(void) {
       /* On x86-64, the kernel does not know how to return from
@@ -2040,7 +1497,7 @@ struct kernel_io_event {
        * Unfortunately, we cannot just reference the glibc version of this
        * function, as glibc goes out of its way to make it inaccessible.
        */
-      void (*res)(void);
+      long long res;
       __asm__ __volatile__("call   2f\n"
                          "0:.align 16\n"
                          "1:movq   %1,%%rax\n"
@@ -2049,7 +1506,7 @@ struct kernel_io_event {
                            "addq   $(1b-0b),%0\n"
                            : "=a" (res)
                            : "i"  (__NR_rt_sigreturn));
-      return res;
+      return (void (*)(void))(uintptr_t)res;
     }
   #elif defined(__arm__)
     /* Most definitions of _syscallX() neglect to mark "memory" as being
@@ -2247,14 +1704,24 @@ struct kernel_io_event {
     #undef LSS_REG
     #define LSS_REG(r,a) register unsigned long __r##r __asm__("$"#r) =       \
                                  (unsigned long)(a)
+
+    #if _MIPS_SIM == _MIPS_SIM_ABI32
+    // See http://sources.redhat.com/ml/libc-alpha/2004-10/msg00050.html
+    // or http://www.linux-mips.org/archives/linux-mips/2004-10/msg00142.html
+    #define MIPS_SYSCALL_CLOBBERS "$1", "$3", "$8", "$9", "$10", "$11", "$12",\
+                                "$13", "$14", "$15", "$24", "$25", "memory"
+    #else
+    #define MIPS_SYSCALL_CLOBBERS "$1", "$3", "$10", "$11", "$12", "$13",     \
+                                "$14", "$15", "$24", "$25", "memory"
+    #endif
+
     #undef  LSS_BODY
     #define LSS_BODY(type,name,r7,...)                                        \
           register unsigned long __v0 __asm__("$2") = __NR_##name;            \
           __asm__ __volatile__ ("syscall\n"                                   \
                                 : "=&r"(__v0), r7 (__r7)                      \
                                 : "0"(__v0), ##__VA_ARGS__                    \
-                                : "$8", "$9", "$10", "$11", "$12",            \
-                                  "$13", "$14", "$15", "$24", "memory");      \
+                                : MIPS_SYSCALL_CLOBBERS);                     \
           LSS_RETURN(type, __v0, __r7)
     #undef _syscall0
     #define _syscall0(type, name)                                             \
@@ -2312,8 +1779,7 @@ struct kernel_io_event {
                               : "=&r"(__v0), "+r" (__r7)                      \
                               : "i" (__NR_##name), "r"(__r4), "r"(__r5),      \
                                 "r"(__r6), "m" ((unsigned long)arg5)          \
-                              : "$8", "$9", "$10", "$11", "$12",              \
-                                "$13", "$14", "$15", "$24", "memory");        \
+                              : MIPS_SYSCALL_CLOBBERS);                       \
         LSS_RETURN(type, __v0, __r7);                                         \
       }
     #else
@@ -2351,10 +1817,9 @@ struct kernel_io_event {
                               ".set reorder\n"                                \
                               : "=&r"(__v0), "+r" (__r7)                      \
                               : "i" (__NR_##name), "r"(__r4), "r"(__r5),      \
-                                "r"(__r6), "r" ((unsigned long)arg5),         \
-                                "r" ((unsigned long)arg6)                     \
-                              : "$8", "$9", "$10", "$11", "$12",              \
-                                "$13", "$14", "$15", "$24", "memory");        \
+                                "r"(__r6), "m" ((unsigned long)arg5),         \
+                                "m" ((unsigned long)arg6)                     \
+                              : MIPS_SYSCALL_CLOBBERS);                       \
         LSS_RETURN(type, __v0, __r7);                                         \
       }
     #else
@@ -2509,13 +1974,13 @@ struct kernel_io_event {
     #define LSS_BODY(nr, type, name, args...)                                 \
         long __sc_ret, __sc_err;                                              \
         {                                                                     \
-                        register unsigned long __sc_0 __asm__ ("r0");         \
-                        register unsigned long __sc_3 __asm__ ("r3");         \
-                        register unsigned long __sc_4 __asm__ ("r4");         \
-                        register unsigned long __sc_5 __asm__ ("r5");         \
-                        register unsigned long __sc_6 __asm__ ("r6");         \
-                        register unsigned long __sc_7 __asm__ ("r7");         \
-                        register unsigned long __sc_8 __asm__ ("r8");         \
+            register unsigned long __sc_0 __asm__ ("r0");                     \
+            register unsigned long __sc_3 __asm__ ("r3");                     \
+            register unsigned long __sc_4 __asm__ ("r4");                     \
+            register unsigned long __sc_5 __asm__ ("r5");                     \
+            register unsigned long __sc_6 __asm__ ("r6");                     \
+            register unsigned long __sc_7 __asm__ ("r7");                     \
+            register unsigned long __sc_8 __asm__ ("r8");                     \
                                                                               \
             LSS_LOADARGS_##nr(name, args);                                    \
             __asm__ __volatile__                                              \
@@ -2572,26 +2037,98 @@ struct kernel_io_event {
                                                type5 arg5, type6 arg6) {      \
           LSS_BODY(6, type, name, arg1, arg2, arg3, arg4, arg5, arg6);        \
        }
-
-    #undef LSS_PPC_MINIMUM_FRAME_SIZE
-    #undef LSS_SIZE_S
-    #ifdef __PPC64__
-      #define LSS_PPC_MINIMUM_FRAME_SIZE 112
-      #define LSS_SIZE_S "d"
-    #else
-      #define LSS_PPC_MINIMUM_FRAME_SIZE 16
-      #define LSS_SIZE_S "w"
-    #endif
-
-    /* clone function adapted from glibc 2.3.6 clone.S                       */
-    /* TODO(user): consider wrapping some args up in a struct, like we
-     * do for i386's _syscall6, so we can compile successfully on gcc 2.95
-     */
+    /* clone function adapted from glibc 2.18 clone.S                       */
     LSS_INLINE int LSS_NAME(clone)(int (*fn)(void *), void *child_stack,
                                    int flags, void *arg, int *parent_tidptr,
                                    void *newtls, int *child_tidptr) {
       long __ret, __err;
       {
+#if defined(__PPC64__)
+
+/* Stack frame offsets.  */
+#if _CALL_ELF != 2
+#define FRAME_MIN_SIZE         112
+#define FRAME_TOC_SAVE         40
+#else
+#define FRAME_MIN_SIZE         32
+#define FRAME_TOC_SAVE         24
+#endif
+
+
+        register int (*__fn)(void *) __asm__ ("r3") = fn;
+        register void *__cstack      __asm__ ("r4") = child_stack;
+        register int __flags         __asm__ ("r5") = flags;
+        register void * __arg        __asm__ ("r6") = arg;
+        register int * __ptidptr     __asm__ ("r7") = parent_tidptr;
+        register void * __newtls     __asm__ ("r8") = newtls;
+        register int * __ctidptr     __asm__ ("r9") = child_tidptr;
+        __asm__ __volatile__(
+            /* check for fn == NULL
+             * and child_stack == NULL
+             */
+            "cmpdi cr0, %6, 0\n\t"
+            "cmpdi cr1, %7, 0\n\t"
+            "cror  cr0*4+eq, cr1*4+eq, cr0*4+eq\n\t"
+            "beq-  cr0, 1f\n\t"
+
+            /* set up stack frame for child                                  */
+            "clrrdi %7, %7, 4\n\t"
+            "li     0, 0\n\t"
+            "stdu   0, -%13(%7)\n\t"
+
+            /* fn, arg, child_stack are saved acrVoss the syscall             */
+            "mr 28, %6\n\t"
+            "mr 29, %7\n\t"
+            "mr 27, %9\n\t"
+
+            /* syscall
+               r3 == flags
+               r4 == child_stack
+               r5 == parent_tidptr
+               r6 == newtls
+               r7 == child_tidptr                                            */
+            "mr 3, %8\n\t"
+            "mr 5, %10\n\t"
+            "mr 6, %11\n\t"
+            "mr 7, %12\n\t"
+            "li 0, %4\n\t"
+            "sc\n\t"
+
+            /* Test if syscall was successful                                */
+            "cmpdi  cr1, 3, 0\n\t"
+            "crandc cr1*4+eq, cr1*4+eq, cr0*4+so\n\t"
+            "bne-   cr1, 1f\n\t"
+
+            /* Do the function call                                          */
+            "std   2, %14(1)\n\t"
+#if _CALL_ELF != 2
+            "ld    0, 0(28)\n\t"
+            "ld    2, 8(28)\n\t"
+            "mtctr 0\n\t"
+#else
+            "mr    12, 28\n\t"
+            "mtctr 12\n\t"
+#endif
+            "mr    3, 27\n\t"
+            "bctrl\n\t"
+            "ld    2, %14(1)\n\t"
+
+            /* Call _exit(r3)                                                */
+            "li 0, %5\n\t"
+            "sc\n\t"
+
+            /* Return to parent                                              */
+            "1:\n\t"
+            "mr %0, 3\n\t"
+              : "=r" (__ret), "=r" (__err)
+              : "0" (-1), "i" (EINVAL),
+                "i" (__NR_clone), "i" (__NR_exit),
+                "r" (__fn), "r" (__cstack), "r" (__flags),
+                "r" (__arg), "r" (__ptidptr), "r" (__newtls),
+                "r" (__ctidptr), "i" (FRAME_MIN_SIZE), "i" (FRAME_TOC_SAVE)
+              : "cr0", "cr1", "memory", "ctr",
+                "r0", "r29", "r27", "r28");
+#else
         register int (*__fn)(void *)    __asm__ ("r8")  = fn;
         register void *__cstack                 __asm__ ("r4")  = child_stack;
         register int __flags                    __asm__ ("r3")  = flags;
@@ -2603,17 +2140,17 @@ struct kernel_io_event {
             /* check for fn == NULL
              * and child_stack == NULL
              */
-            "cmp" LSS_SIZE_S "i cr0, %6, 0\n\t"
-            "cmp" LSS_SIZE_S "i cr1, %7, 0\n\t"
+            "cmpwi cr0, %6, 0\n\t"
+            "cmpwi cr1, %7, 0\n\t"
             "cror cr0*4+eq, cr1*4+eq, cr0*4+eq\n\t"
             "beq- cr0, 1f\n\t"

             /* set up stack frame for child                                  */
-            "clrr" LSS_SIZE_S "i %7, %7, 4\n\t"
+            "clrrwi %7, %7, 4\n\t"
             "li 0, 0\n\t"
-            "st" LSS_SIZE_S "u 0, %13(%7)\n\t"
+            "stwu 0, -16(%7)\n\t"

-            /* fn, arg, child_stack are saved across the syscall: r27-29     */
+            /* fn, arg, child_stack are saved across the syscall: r28-30     */
             "mr 28, %6\n\t"
             "mr 29, %7\n\t"
             "mr 27, %9\n\t"
@@ -2629,304 +2166,403 @@ struct kernel_io_event {
             "sc\n\t"

             /* Test if syscall was successful                                */
-            "cmp" LSS_SIZE_S "i cr1, 3, 0\n\t"
+            "cmpwi cr1, 3, 0\n\t"
             "crandc cr1*4+eq, cr1*4+eq, cr0*4+so\n\t"
             "bne- cr1, 1f\n\t"

-            /* Do the function call.  On PowerPC64, a function pointer points
-             * a function descriptor instead of the first instruction.  We need
-             * to load the callee's entry point and TOC from the descriptor.
-             * Since the callee may have a differet TOC, we also need to
-             * save and restore caller's TOC around the call.
-             */
-
-    #ifdef __PPC64__
-            "std 2, 40(1)\n\t"  /* Save caller's TOC. */
-            "ld 4, 0(28)\n\t"   /* Get callee's entry address. */
-            "ld 2, 8(28)\n\t"   /* Load calee's TOC. */
-            "mtctr 4\n\t"
+            /* Do the function call                                          */
+            "mtctr 28\n\t"
             "mr 3, 27\n\t"
             "bctrl\n\t"
-            "ld 2, 40(1)\n\t"  /* Restore caller's TOC after call. */
+
+            /* Call _exit(r3)                                                */
+            "li 0, %5\n\t"
+            "sc\n\t"
+
+            /* Return to parent                                              */
+            "1:\n"
+            "mfcr %1\n\t"
+            "mr %0, 3\n\t"
+              : "=r" (__ret), "=r" (__err)
+              : "0" (-1), "1" (EINVAL),
+                "i" (__NR_clone), "i" (__NR_exit),
+                "r" (__fn), "r" (__cstack), "r" (__flags),
+                "r" (__arg), "r" (__ptidptr), "r" (__newtls),
+                "r" (__ctidptr)
+              : "cr0", "cr1", "memory", "ctr",
+                "r0", "r29", "r27", "r28");
+
+#endif
+      }
+      LSS_RETURN(int, __ret, __err);
+    }
+  #elif defined(__aarch64__)
+    #undef LSS_REG
+    #define LSS_REG(r,a) register long __x##r __asm__("x"#r) = (long)a
+    #undef  LSS_BODY
+    #define LSS_BODY(type,name,args...)                                       \
+          register long __res_x0 __asm__("x0");                               \
+          long __res;                                                         \
+          __asm__ __volatile__ ("mov x8, %1\n"                                \
+                                "svc 0x0\n"                                   \
+                                : "=r"(__res_x0)                              \
+                                : "i"(__NR_##name) , ## args                  \
+                                : "memory");                                  \
+          __res = __res_x0;                                                   \
+          LSS_RETURN(type, __res)
+    #undef _syscall0
+    #define _syscall0(type, name)                                             \
+      type LSS_NAME(name)(void) {                                             \
+        LSS_BODY(type, name);                                                 \
+      }
+    #undef _syscall1
+    #define _syscall1(type, name, type1, arg1)                                \
+      type LSS_NAME(name)(type1 arg1) {                                       \
+        LSS_REG(0, arg1); LSS_BODY(type, name, "r"(__x0));                    \
+      }
+    #undef _syscall2
+    #define _syscall2_long(type, name, svc, type1, arg1, type2, arg2)         \
+      type LSS_NAME(name)(type1 arg1, type2 arg2) {                           \
+        LSS_REG(0, arg1); LSS_REG(1, arg2);                                   \
+        LSS_BODY(type, svc, "r"(__x0), "r"(__x1));                            \
+      }
+    #define _syscall2(type, name, type1, arg1, type2, arg2)                   \
+            _syscall2_long(type, name, name, type1, arg1, type2, arg2)
+    #undef _syscall3
+    #define _syscall3_long(type, name, svc, type1, arg1, type2, arg2,         \
+                           type3, arg3)                                       \
+      type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3) {               \
+        LSS_REG(0, arg1); LSS_REG(1, arg2); LSS_REG(2, arg3);                 \
+        LSS_BODY(type, svc, "r"(__x0), "r"(__x1), "r"(__x2));                 \
+      }
+    #define _syscall3(type, name, type1, arg1, type2, arg2, type3, arg3)      \
+            _syscall3_long(type, name, name, type1, arg1, type2, arg2,        \
+                           type3, arg3)
+    #undef _syscall4
+    #define _syscall4(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4)  \
+      type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3, type4 arg4) {   \
+        LSS_REG(0, arg1); LSS_REG(1, arg2); LSS_REG(2, arg3);                 \
+        LSS_REG(3, arg4);                                                     \
+        LSS_BODY(type, name, "r"(__x0), "r"(__x1), "r"(__x2), "r"(__x3));     \
+      }
+    #undef _syscall5
+    #define _syscall5(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,  \
+                      type5,arg5)                                             \
+      type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3, type4 arg4,     \
+                          type5 arg5) {                                       \
+        LSS_REG(0, arg1); LSS_REG(1, arg2); LSS_REG(2, arg3);                 \
+        LSS_REG(3, arg4); LSS_REG(4, arg5);                                   \
+        LSS_BODY(type, name, "r"(__x0), "r"(__x1), "r"(__x2), "r"(__x3),      \
+                             "r"(__x4));                                      \
+      }
+    #undef _syscall6
+    #define _syscall6_long(type,name,svc,type1,arg1,type2,arg2,type3,arg3,    \
+                           type4,arg4,type5,arg5,type6,arg6)                  \
+      type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3, type4 arg4,     \
+                          type5 arg5, type6 arg6) {                           \
+        LSS_REG(0, arg1); LSS_REG(1, arg2); LSS_REG(2, arg3);                 \
+        LSS_REG(3, arg4); LSS_REG(4, arg5); LSS_REG(5, arg6);                 \
+        LSS_BODY(type, svc, "r"(__x0), "r"(__x1), "x"(__x2), "r"(__x3),       \
+                             "r"(__x4), "r"(__x5));                           \
+      }
+    #define _syscall6(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,  \
+                      type5,arg5,type6,arg6)                                  \
+            _syscall6_long(type,name,name,type1,arg1,type2,arg2,type3,arg3,   \
+                           type4,arg4,type5,arg5,type6,arg6)
+    /* clone function adapted from glibc 2.18 clone.S                       */
+    LSS_INLINE int LSS_NAME(clone)(int (*fn)(void *), void *child_stack,
+                                   int flags, void *arg, int *parent_tidptr,
+                                   void *newtls, int *child_tidptr) {
+      long __res;
+      {
+        register int (*__fn)(void *)  __asm__("x0") = fn;
+        register void *__stack __asm__("x1") = child_stack;
+        register int   __flags __asm__("x2") = flags;
+        register void *__arg   __asm__("x3") = arg;
+        register int  *__ptid  __asm__("x4") = parent_tidptr;
+        register void *__tls   __asm__("x5") = newtls;
+        register int  *__ctid  __asm__("x6") = child_tidptr;
+        __asm__ __volatile__(/* if (fn == NULL || child_stack == NULL)
+                              *   return -EINVAL;
+                              */
+                             "cbz     x0,1f\n"
+                             "cbz     x1,1f\n"
+
+                             /* Push "arg" and "fn" onto the stack that will be
+                              * used by the child.
+                              */
+                             "stp x0,x3, [x1, #-16]!\n"
+
+                             "mov x0,x2\n" /* flags  */
+                             "mov x2,x4\n" /* ptid  */
+                             "mov x3,x5\n" /* tls */
+                             "mov x4,x6\n" /* ctid */
+                             "mov x8,%9\n" /* clone */
+
+                             "svc 0x0\n"
+
+                             /* if (%r0 != 0)
+                              *   return %r0;
+                              */
+                             "cmp x0, #0\n"
+                             "bne 2f\n"
+
+                             /* In the child, now. Call "fn(arg)".
+                              */
+                             "ldp x1, x0, [sp], #16\n"
+                             "blr x1\n"
+
+                             /* Call _exit(%r0).
+                              */
+                             "mov x8, %10\n"
+                             "svc 0x0\n"
+                           "1:\n"
+                             "mov x8, %1\n"
+                           "2:\n"
+                             : "=r" (__res)
+                             : "i"(-EINVAL),
+                               "r"(__fn), "r"(__stack), "r"(__flags), "r"(__arg),
+                               "r"(__ptid), "r"(__tls), "r"(__ctid),
+                               "i"(__NR_clone), "i"(__NR_exit)
+                             : "x30", "memory");
+      }
+      LSS_RETURN(int, __res);
+    }
+  #elif defined(__s390__)
+    #undef  LSS_REG
+    #define LSS_REG(r, a) register unsigned long __r##r __asm__("r"#r) = (unsigned long) a
+    #undef  LSS_BODY
+    #define LSS_BODY(type, name, args...)                                     \
+        register unsigned long __nr __asm__("r1")                             \
+            = (unsigned long)(__NR_##name);                                   \
+        register long __res_r2 __asm__("r2");                                 \
+        long __res;                                                           \
+        __asm__ __volatile__                                                  \
+            ("svc 0\n\t"                                                      \
+             : "=d"(__res_r2)                                                 \
+             : "d"(__nr), ## args                                             \
+             : "memory");                                                     \
+        __res = __res_r2;                                                     \
+        LSS_RETURN(type, __res)
+    #undef _syscall0
+    #define _syscall0(type, name)                                             \
+       type LSS_NAME(name)(void) {                                            \
+          LSS_BODY(type, name);                                               \
+       }
+    #undef _syscall1
+    #define _syscall1(type, name, type1, arg1)                                \
+       type LSS_NAME(name)(type1 arg1) {                                      \
+          LSS_REG(2, arg1);                                                   \
+          LSS_BODY(type, name, "0"(__r2));                                    \
+       }
+    #undef _syscall2
+    #define _syscall2(type, name, type1, arg1, type2, arg2)                   \
+       type LSS_NAME(name)(type1 arg1, type2 arg2) {                          \
+          LSS_REG(2, arg1); LSS_REG(3, arg2);                                 \
+          LSS_BODY(type, name, "0"(__r2), "d"(__r3));                         \
+       }
+    #undef _syscall3
+    #define _syscall3(type, name, type1, arg1, type2, arg2, type3, arg3)      \
+       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3) {              \
+          LSS_REG(2, arg1); LSS_REG(3, arg2); LSS_REG(4, arg3);               \
+          LSS_BODY(type, name, "0"(__r2), "d"(__r3), "d"(__r4));              \
+       }
+    #undef _syscall4
+    #define _syscall4(type, name, type1, arg1, type2, arg2, type3, arg3,      \
+                                  type4, arg4)                                \
+       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3,                \
+                           type4 arg4) {                                      \
+          LSS_REG(2, arg1); LSS_REG(3, arg2); LSS_REG(4, arg3);               \
+          LSS_REG(5, arg4);                                                   \
+          LSS_BODY(type, name, "0"(__r2), "d"(__r3), "d"(__r4),               \
+                               "d"(__r5));                                    \
+       }
+    #undef _syscall5
+    #define _syscall5(type, name, type1, arg1, type2, arg2, type3, arg3,      \
+                                  type4, arg4, type5, arg5)                   \
+       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3,                \
+                           type4 arg4, type5 arg5) {                          \
+          LSS_REG(2, arg1); LSS_REG(3, arg2); LSS_REG(4, arg3);               \
+          LSS_REG(5, arg4); LSS_REG(6, arg5);                                 \
+          LSS_BODY(type, name, "0"(__r2), "d"(__r3), "d"(__r4),               \
+                               "d"(__r5), "d"(__r6));                         \
+       }
+    #undef _syscall6
+    #define _syscall6(type, name, type1, arg1, type2, arg2, type3, arg3,      \
+                                  type4, arg4, type5, arg5, type6, arg6)      \
+       type LSS_NAME(name)(type1 arg1, type2 arg2, type3 arg3,                \
+                           type4 arg4, type5 arg5, type6 arg6) {              \
+          LSS_REG(2, arg1); LSS_REG(3, arg2); LSS_REG(4, arg3);               \
+          LSS_REG(5, arg4); LSS_REG(6, arg5); LSS_REG(7, arg6);               \
+          LSS_BODY(type, name, "0"(__r2), "d"(__r3), "d"(__r4),               \
+                               "d"(__r5), "d"(__r6), "d"(__r7));              \
+       }
+    LSS_INLINE int LSS_NAME(clone)(int (*fn)(void *), void *child_stack,
+                                   int flags, void *arg, int *parent_tidptr,
+                                   void *newtls, int *child_tidptr) {
+      long __ret;
+      {
+        register int  (*__fn)(void *)    __asm__ ("r1")  = fn;
+        register void  *__cstack         __asm__ ("r2")  = child_stack;
+        register int    __flags          __asm__ ("r3")  = flags;
+        register void  *__arg            __asm__ ("r0")  = arg;
+        register int   *__ptidptr        __asm__ ("r4")  = parent_tidptr;
+        register void  *__newtls         __asm__ ("r6")  = newtls;
+        register int   *__ctidptr        __asm__ ("r5")  = child_tidptr;
+        __asm__ __volatile__ (
+    #ifndef __s390x__
+                                  /* arg already in r0 */
+          "ltr %4, %4\n\t"        /* check fn, which is already in r1 */
+          "jz 1f\n\t"             /* NULL function pointer, return -EINVAL */
+          "ltr %5, %5\n\t"        /* check child_stack, which is already in r2 */
+          "jz 1f\n\t"             /* NULL stack pointer, return -EINVAL */
+                                  /* flags already in r3 */
+                                  /* parent_tidptr already in r4 */
+                                  /* child_tidptr already in r5 */
+                                  /* newtls already in r6 */
+          "svc %2\n\t"            /* invoke clone syscall */
+          "ltr %0,%%r2\n\t"       /* load return code into __ret and test */
+          "jnz 1f\n\t"            /* return to parent if non-zero */
+                                  /* start child thread */
+          "lr %%r2, %7\n\t"       /* set first parameter to void *arg */
+          "ahi %%r15, -96\n\t"    /* make room on the stack for the save area */
+          "xc 0(4,%%r15), 0(%%r15)\n\t"
+          "basr %%r14, %4\n\t"    /* jump to fn */
+          "svc %3\n"              /* invoke exit syscall */
+          "1:\n"
     #else
-            "mtctr 28\n\t"
-            "mr 3, 27\n\t"
-            "bctrl\n\t"
+                                  /* arg already in r0 */
+          "ltgr %4, %4\n\t"       /* check fn, which is already in r1 */
+          "jz 1f\n\t"             /* NULL function pointer, return -EINVAL */
+          "ltgr %5, %5\n\t"       /* check child_stack, which is already in r2 */
+          "jz 1f\n\t"             /* NULL stack pointer, return -EINVAL */
+                                  /* flags already in r3 */
+                                  /* parent_tidptr already in r4 */
+                                  /* child_tidptr already in r5 */
+                                  /* newtls already in r6 */
+          "svc %2\n\t"            /* invoke clone syscall */
+          "ltgr %0, %%r2\n\t"     /* load return code into __ret and test */
+          "jnz 1f\n\t"            /* return to parent if non-zero */
+                                  /* start child thread */
+          "lgr %%r2, %7\n\t"      /* set first parameter to void *arg */
+          "aghi %%r15, -160\n\t"  /* make room on the stack for the save area */
+          "xc 0(8,%%r15), 0(%%r15)\n\t"
+          "basr %%r14, %4\n\t"    /* jump to fn */
+          "svc %3\n"              /* invoke exit syscall */
+          "1:\n"
     #endif
-
-            /* Call _exit(r3)                                                */
-            "li 0, %5\n\t"
-            "sc\n\t"
-
-            /* Return to parent                                              */
-            "1:\n"
-            "mfcr %1\n\t"
-            "mr %0, 3\n\t"
-              : "=r" (__ret), "=r" (__err)
-              : "0" (-1), "1" (EINVAL),
-                "i" (__NR_clone), "i" (__NR_exit),
-                "r" (__fn), "r" (__cstack), "r" (__flags),
-                "r" (__arg), "r" (__ptidptr), "r" (__newtls),
-                "r" (__ctidptr), "i"(-LSS_PPC_MINIMUM_FRAME_SIZE)
-              : "cr0", "cr1", "memory", "ctr",
-                "r0", "r29", "r27", "r28");
+          : "=r" (__ret)
+          : "0" (-EINVAL), "i" (__NR_clone), "i" (__NR_exit),
+            "d" (__fn), "d" (__cstack), "d" (__flags), "d" (__arg),
+            "d" (__ptidptr), "d" (__newtls), "d" (__ctidptr)
+          : "cc", "r14", "memory"
+        );
       }
-      LSS_RETURN(int, __ret, __err);
+      LSS_RETURN(int, __ret);
     }
-  #ifdef __PPC64__
-    LSS_INLINE _syscall4(int, fadvise64, int, fd, loff_t, offset, loff_t, len,
-                         int,  advice)
-  #else
-    /* fadvise64 wrapper not yet implemented for 32-bit PowerPC.  */
   #endif
-  #endif  /* defined (__PPC__) */
   #define __NR__exit   __NR_exit
   #define __NR__gettid __NR_gettid
   #define __NR__mremap __NR_mremap
-  LSS_INLINE _syscall1(int,     brk,             void *,      e)
-  LSS_INLINE _syscall2(int,     capset,
-                       struct kernel_cap_user_header*, h,
-                       struct kernel_cap_user_data*, d)
-  LSS_INLINE _syscall1(int,     chdir,           const char *,p)
-  LSS_INLINE _syscall1(int,     chroot,          const char *,p)
   LSS_INLINE _syscall1(int,     close,           int,         f)
-  LSS_INLINE _syscall2(int,     clock_getres,    int,         c,
-                       struct kernel_timespec*, t)
-  LSS_INLINE _syscall2(int,     clock_gettime,   int,         c,
-                       struct kernel_timespec*, t)
-  LSS_INLINE _syscall1(int,     dup,             int,         f)
-  LSS_INLINE _syscall2(int,     dup2,            int,         s,
-                       int,            d)
-  LSS_INLINE _syscall3(int,     execve,          const char*, f,
-                       const char*const*,a,const char*const*, e)
   LSS_INLINE _syscall1(int,     _exit,           int,         e)
-  LSS_INLINE _syscall1(int,     exit_group,      int,         e)
+#if defined(__aarch64__) && defined (__ILP32__)
+  /* aarch64_ilp32 uses fcntl64 for sys_fcntl() */
+  LSS_INLINE _syscall3_long(int,     fcntl,      fcntl64,     int,         f,
+                       int,            c, long,   a)
+#else
   LSS_INLINE _syscall3(int,     fcntl,           int,         f,
                        int,            c, long,   a)
-  LSS_INLINE _syscall0(pid_t,   fork)
+#endif
+#if defined(__aarch64__) && defined (__ILP32__)
+  /* aarch64_ilp32 uses fstat64 for sys_fstat() */
+  LSS_INLINE _syscall2_long(int,     fstat,       fstat64,    int,         f,
+                      struct kernel_stat*,   b)
+#else
   LSS_INLINE _syscall2(int,     fstat,           int,         f,
                       struct kernel_stat*,   b)
-  LSS_INLINE _syscall2(int,     fstatfs,         int,         f,
-                      struct kernel_statfs*, b)
-  LSS_INLINE _syscall2(int, ftruncate,           int,         f,
-                       off_t,          l)
-  LSS_INLINE _syscall4(int,     futex,           int*,        a,
+#endif
+  LSS_INLINE _syscall6(int,     futex,           int*,        a,
                        int,            o, int,    v,
-                      struct kernel_timespec*, t)
-  LSS_INLINE _syscall3(int,     getdents,        int,         f,
-                      struct kernel_dirent*, d, int,    c)
-  LSS_INLINE _syscall3(int,     getdents64,      int,         f,
-                      struct kernel_dirent64*, d, int,    c)
-  LSS_INLINE _syscall0(gid_t,   getegid)
-  LSS_INLINE _syscall0(uid_t,   geteuid)
-  LSS_INLINE _syscall0(pid_t,   getpgrp)
+                      struct kernel_timespec*, t,
+                       int*, a2,
+                       int, v3)
+#ifdef __NR_getdents64
+    LSS_INLINE _syscall3(int,     getdents64,      int,         f,
+                         struct kernel_dirent64*, d, int,    c)
+#define KERNEL_DIRENT kernel_dirent64
+#define GETDENTS sys_getdents64
+#else
+    LSS_INLINE _syscall3(int,     getdents,        int,         f,
+                         struct kernel_dirent*, d, int,    c)
+#define KERNEL_DIRENT kernel_dirent
+#define GETDENTS sys_getdents
+#endif
   LSS_INLINE _syscall0(pid_t,   getpid)
   LSS_INLINE _syscall0(pid_t,   getppid)
-  LSS_INLINE _syscall2(int,     getpriority,     int,         a,
-                       int,            b)
-  LSS_INLINE _syscall3(int,     getresgid,       gid_t *,     r,
-                       gid_t *,         e,       gid_t *,     s)
-  LSS_INLINE _syscall3(int,     getresuid,       uid_t *,     r,
-                       uid_t *,         e,       uid_t *,     s)
-  #ifndef __ARM_EABI__
-  /* No available on ARM EABI Linux.  */
-  LSS_INLINE _syscall2(int,     getrlimit,       int,         r,
-                      struct kernel_rlimit*, l)
-  #endif
-  LSS_INLINE _syscall1(pid_t,   getsid,          pid_t,       p)
   LSS_INLINE _syscall0(pid_t,   _gettid)
-  LSS_INLINE _syscall2(int,     gettimeofday,    struct timeval *, v,
-                       struct timezone *, z)
-  LSS_INLINE _syscall5(int,     setxattr,        const char *,p,
-                       const char *,   n,        const void *,v,
-                       size_t,         s,        int,         f)
-  LSS_INLINE _syscall5(int,     lsetxattr,       const char *,p,
-                       const char *,   n,        const void *,v,
-                       size_t,         s,        int,         f)
-  LSS_INLINE _syscall4(ssize_t, getxattr,        const char *,p,
-                       const char *,   n,        void *,      v, size_t, s)
-  LSS_INLINE _syscall4(ssize_t, lgetxattr,       const char *,p,
-                       const char *,   n,        void *,      v, size_t, s)
-  LSS_INLINE _syscall3(ssize_t, listxattr,       const char *,p,
-                       char *,   l,              size_t,      s)
-  LSS_INLINE _syscall3(ssize_t, llistxattr,      const char *,p,
-                       char *,   l,              size_t,      s)
-  LSS_INLINE _syscall3(int,     ioctl,           int,         d,
-                       int,     r,               void *,      a)
-  LSS_INLINE _syscall2(int,     ioprio_get,      int,         which,
-                       int,     who)
-  LSS_INLINE _syscall3(int,     ioprio_set,      int,         which,
-                       int,     who,             int,         ioprio)
   LSS_INLINE _syscall2(int,     kill,            pid_t,       p,
                        int,            s)
-  LSS_INLINE _syscall3(off_t,   lseek,           int,         f,
-                       off_t,          o, int,    w)
+  #if defined(__x86_64__)
+    /* Need to make sure off_t isn't truncated to 32-bits under x32.  */
+    LSS_INLINE off_t LSS_NAME(lseek)(int f, off_t o, int w) {
+      _LSS_BODY(3, off_t, lseek, off_t, LSS_SYSCALL_ARG(f), (uint64_t)(o),
+                                        LSS_SYSCALL_ARG(w));
+    }
+  #elif defined(__aarch64__) && defined (__ILP32__)
+    /* aarch64_ilp32 uses llseek for sys_lseek() */
+    LSS_INLINE _syscall3_long(off_t,   lseek,       llseek,    int,         f,
+                         off_t,          o, int,    w)
+  #else
+    LSS_INLINE _syscall3(off_t,   lseek,           int,         f,
+                         off_t,          o, int,    w)
+  #endif
   LSS_INLINE _syscall2(int,     munmap,          void*,       s,
                        size_t,         l)
-  LSS_INLINE _syscall6(long,    move_pages,      pid_t,       p,
-                       unsigned long,  n, void **,g, int *,   d,
-                       int *,          s, int,    f)
-  LSS_INLINE _syscall3(int,     mprotect,        const void *,a,
-                       size_t,         l,        int,         p)
   LSS_INLINE _syscall5(void*,   _mremap,         void*,       o,
                        size_t,         os,       size_t,      ns,
                        unsigned long,  f, void *, a)
-  LSS_INLINE _syscall3(int,     open,            const char*, p,
-                       int,            f, int,    m)
-  LSS_INLINE _syscall3(int,     poll,           struct kernel_pollfd*, u,
-                       unsigned int,   n, int,    t)
   LSS_INLINE _syscall2(int,     prctl,           int,         o,
                        long,           a)
-  LSS_INLINE _syscall5(int, mount, const char *, source, const char *, target,
-                       const char *, filesystemtype, unsigned long, mountflags,
-                       const void *, data)
-  LSS_INLINE _syscall1(int, unshare, int, flags)
-  LSS_INLINE _syscall2(int, setns, int, fd, int, nstype)
-  #if defined(__NR_preadv)
-    // Defined on x86_64 / i386 only
-  LSS_INLINE _syscall5(ssize_t, preadv, unsigned long, fd,
-                       const struct kernel_iovec*, iovec,
-                       unsigned long, vlen, unsigned long, pos_l,
-                       unsigned long, pos_h)
-  #endif
   LSS_INLINE _syscall4(long,    ptrace,          int,         r,
                        pid_t,          p, void *, a, void *, d)
-  #if defined(__NR_pwritev)
-    // Defined on x86_64 / i386 only
-  LSS_INLINE _syscall5(ssize_t, pwritev, unsigned long, fd,
-                       const struct kernel_iovec*, iovec,
-                       unsigned long, vlen, unsigned long, pos_l,
-                       unsigned long, pos_h)
-  #endif
-  #if defined(__NR_quotactl)
-    // Defined on x86_64 / i386 only
-    LSS_INLINE _syscall4(int,  quotactl,  int,  cmd,  const char *, special,
-                         int, id, caddr_t, addr)
-  #endif
   LSS_INLINE _syscall3(ssize_t, read,            int,         f,
                        void *,         b, size_t, c)
-  LSS_INLINE _syscall3(int,     readlink,        const char*, p,
-                       char*,          b, size_t, s)
   LSS_INLINE _syscall4(int,     rt_sigaction,    int,         s,
                        const struct kernel_sigaction*, a,
                        struct kernel_sigaction*, o, size_t,   c)
-  LSS_INLINE _syscall2(int, rt_sigpending, struct kernel_sigset_t *, s,
-                       size_t,         c)
   LSS_INLINE _syscall4(int, rt_sigprocmask,      int,         h,
                        const struct kernel_sigset_t*,  s,
                        struct kernel_sigset_t*,        o, size_t, c);
-  LSS_INLINE _syscall1(int, rt_sigreturn,        unsigned long, u);
-  LSS_INLINE _syscall2(int, rt_sigsuspend,
-                       const struct kernel_sigset_t*, s,  size_t, c);
-  LSS_INLINE _syscall3(int,     sched_getaffinity,pid_t,      p,
-                       unsigned int,   l, unsigned long *, m)
-  LSS_INLINE _syscall3(int,     sched_setaffinity,pid_t,      p,
-                       unsigned int,   l, unsigned long *, m)
   LSS_INLINE _syscall0(int,     sched_yield)
-  LSS_INLINE _syscall1(long,    set_tid_address, int *,       t)
-  LSS_INLINE _syscall1(int,     setfsgid,        gid_t,       g)
-  LSS_INLINE _syscall1(int,     setfsuid,        uid_t,       u)
-  LSS_INLINE _syscall1(int,     setuid,          uid_t,       u)
-  LSS_INLINE _syscall1(int,     setgid,          gid_t,       g)
-  LSS_INLINE _syscall2(int,     setpgid,         pid_t,       p,
-                       pid_t,          g)
-  LSS_INLINE _syscall3(int,     setpriority,     int,         a,
-                       int,            b, int,    p)
-  LSS_INLINE _syscall3(int,     setresgid,       gid_t,       r,
-                       gid_t,          e, gid_t,  s)
-  LSS_INLINE _syscall3(int,     setresuid,       uid_t,       r,
-                       uid_t,          e, uid_t,  s)
-  LSS_INLINE _syscall2(int,     setrlimit,       int,         r,
-                       const struct kernel_rlimit*, l)
-  LSS_INLINE _syscall0(pid_t,    setsid)
   LSS_INLINE _syscall2(int,     sigaltstack,     const stack_t*, s,
                        const stack_t*, o)
-  #if defined(__NR_sigreturn)
-  LSS_INLINE _syscall1(int,     sigreturn,       unsigned long, u);
+  #if defined(__NR_fstatat)
+    LSS_INLINE _syscall4(int, fstatat, int, d, const char *, p,
+                         struct kernel_stat*,   b, int, flags)
+    LSS_INLINE int LSS_NAME(stat)(const char* p, struct kernel_stat* b) {
+      return LSS_NAME(fstatat)(AT_FDCWD,p,b,0);
+  }
+  #else
+    LSS_INLINE _syscall2(int,     stat,            const char*, f,
+                         struct kernel_stat*,   b)
   #endif
-  LSS_INLINE _syscall2(int,     stat,            const char*, f,
-                      struct kernel_stat*,   b)
-  LSS_INLINE _syscall2(int,     statfs,          const char*, f,
-                      struct kernel_statfs*, b)
-  LSS_INLINE _syscall3(int,     tgkill,          pid_t,       p,
-                       pid_t,          t, int,            s)
-  LSS_INLINE _syscall2(int,     tkill,           pid_t,       p,
-                       int,            s)
   LSS_INLINE _syscall3(ssize_t, write,            int,        f,
                        const void *,   b, size_t, c)
-  LSS_INLINE _syscall3(ssize_t, writev,           int,        f,
-                       const struct kernel_iovec*, v, size_t, c)
-  LSS_INLINE _syscall1(int,     umask,           unsigned,    m)
-  LSS_INLINE _syscall1(int,     unlink,          const char*, f)
   #if defined(__NR_getcpu)
     LSS_INLINE _syscall3(long, getcpu, unsigned *, cpu,
                          unsigned *, node, void *, unused);
   #endif
-  #if defined(__x86_64__) ||                                                  \
+  #if defined(__x86_64__) || defined(__aarch64__) || \
      (defined(__mips__) && _MIPS_SIM != _MIPS_SIM_ABI32)
-    LSS_INLINE _syscall3(int, recvmsg,            int,   s,
-                        struct kernel_msghdr*,     m, int, f)
-    LSS_INLINE _syscall3(int, sendmsg,            int,   s,
-                         const struct kernel_msghdr*, m, int, f)
-    LSS_INLINE _syscall6(int, sendto,             int,   s,
-                         const void*,             m, size_t, l,
-                         int,                     f,
-                         const struct kernel_sockaddr*, a, int, t)
-    LSS_INLINE _syscall2(int, shutdown,           int,   s,
-                         int,                     h)
     LSS_INLINE _syscall3(int, socket,             int,   d,
                          int,                     t, int,       p)
-    LSS_INLINE _syscall4(int, socketpair,         int,   d,
-                         int,                     t, int,       p, int*, s)
   #endif
-
-  #if defined(__x86_64__) || defined(__PPC__)
-    LSS_INLINE int LSS_NAME(getresgid32)(gid_t *rgid,
-                                         gid_t *egid,
-                                         gid_t *sgid) {
-      return LSS_NAME(getresgid)(rgid, egid, sgid);
-    }
-
-    LSS_INLINE int LSS_NAME(getresuid32)(uid_t *ruid,
-                                         uid_t *euid,
-                                         uid_t *suid) {
-      return LSS_NAME(getresuid)(ruid, euid, suid);
-    }
-
-    LSS_INLINE _syscall4(int, newfstatat,         int,   d,
-                         const char *,            p,
-                        struct kernel_stat*,       b, int, f)
-
-    LSS_INLINE int LSS_NAME(setfsgid32)(gid_t gid) {
-      return LSS_NAME(setfsgid)(gid);
-    }
-
-    LSS_INLINE int LSS_NAME(setfsuid32)(uid_t uid) {
-      return LSS_NAME(setfsuid)(uid);
-    }
-
-    LSS_INLINE int LSS_NAME(setresgid32)(gid_t rgid, gid_t egid, gid_t sgid) {
-      return LSS_NAME(setresgid)(rgid, egid, sgid);
-    }
-
-    LSS_INLINE int LSS_NAME(setresuid32)(uid_t ruid, uid_t euid, uid_t suid) {
-      return LSS_NAME(setresuid)(ruid, euid, suid);
-    }
-  #endif // defined(__x86_64__) || defined(__PPC__)
-
-  #if defined(__x86_64__) || defined(__PPC64__)
-    LSS_INLINE _syscall4(int, fallocate, int, fd, int, mode,
-                         loff_t, offset, loff_t, len)
-
-    LSS_INLINE _syscall6(void*, mmap,              void*, s,
-                         size_t,                   l, int,               p,
-                         int,                      f, int,               d,
-                         __off64_t,                o)
-
+  #if defined(__x86_64__) || defined(__s390x__)
     LSS_INLINE int LSS_NAME(sigaction)(int signum,
                                        const struct kernel_sigaction *act,
                                        struct kernel_sigaction *oldact) {
-    #if defined(__x86_64__)
+      #if defined(__x86_64__)
       /* On x86_64, the kernel requires us to always set our own
        * SA_RESTORER in order to be able to return from a signal handler.
        * This function must have a "magic" signature that the "gdb"
@@ -2938,17 +2574,10 @@ struct kernel_io_event {
         a.sa_restorer = LSS_NAME(restore_rt)();
         return LSS_NAME(rt_sigaction)(signum, &a, oldact,
                                       (KERNEL_NSIG+7)/8);
-      } else {
+      } else
+      #endif
         return LSS_NAME(rt_sigaction)(signum, act, oldact,
                                       (KERNEL_NSIG+7)/8);
-      }
-    #else
-      return LSS_NAME(rt_sigaction)(signum, act, oldact, (KERNEL_NSIG+7)/8);
-    #endif
-    }
-
-    LSS_INLINE int LSS_NAME(sigpending)(struct kernel_sigset_t *set) {
-      return LSS_NAME(rt_sigpending)(set, (KERNEL_NSIG+7)/8);
     }

     LSS_INLINE int LSS_NAME(sigprocmask)(int how,
@@ -2956,178 +2585,41 @@ struct kernel_io_event {
                                          struct kernel_sigset_t *oldset) {
       return LSS_NAME(rt_sigprocmask)(how, set, oldset, (KERNEL_NSIG+7)/8);
     }
+  #endif
+  #if (defined(__aarch64__)) || \
+      (defined(__mips__) \
+       && (_MIPS_SIM == _MIPS_SIM_ABI64 || _MIPS_SIM == _MIPS_SIM_NABI32))
+    LSS_INLINE int LSS_NAME(sigaction)(int signum,
+                                       const struct kernel_sigaction *act,
+                                       struct kernel_sigaction *oldact) {
+        return LSS_NAME(rt_sigaction)(signum, act, oldact, (KERNEL_NSIG+7)/8);

-    LSS_INLINE int LSS_NAME(sigsuspend)(const struct kernel_sigset_t *set) {
-      return LSS_NAME(rt_sigsuspend)(set, (KERNEL_NSIG+7)/8);
     }
-  #endif /* defined(__x86_64__) || defined(__PPC64__) */
-
-  #if defined(__x86_64__) || \
-      defined(__arm__) || \
-     (defined(__mips__) && _MIPS_SIM != _MIPS_SIM_ABI32)
+    LSS_INLINE int LSS_NAME(sigprocmask)(int how,
+                                         const struct kernel_sigset_t *set,
+                                         struct kernel_sigset_t *oldset) {
+      return LSS_NAME(rt_sigprocmask)(how, set, oldset, (KERNEL_NSIG+7)/8);
+    }
+  #endif
+  #ifdef __NR_wait4
     LSS_INLINE _syscall4(pid_t, wait4,            pid_t, p,
                          int*,                    s, int,       o,
-                        struct kernel_rusage*,     r)
-
+                         struct kernel_rusage*,   r)
     LSS_INLINE pid_t LSS_NAME(waitpid)(pid_t pid, int *status, int options){
       return LSS_NAME(wait4)(pid, status, options, 0);
     }
+  #else
+    LSS_INLINE _syscall3(pid_t, waitpid,          pid_t, p,
+                         int*,              s,    int,   o)
   #endif
-  #if defined(__x86_64__)|| \
-      defined(__ARM_ARCH_3__) || defined(__ARM_ARCH_5T__) || \
-      defined(__mips__) || defined(__PPC__)
-    LSS_INLINE _syscall2(int,     setgroups,     size_t,      c,
-                         const gid_t *,  g)
-  #endif
-  #if defined(__i386__) || defined(__x86_64__) || defined(__arm__) || \
-      defined(__PPC__)
+  #ifdef __NR_openat
     LSS_INLINE _syscall4(int, openat, int, d, const char *, p, int, f, int, m)
-    LSS_INLINE _syscall3(int, unlinkat, int, d, const char *, p, int, f)
-  #endif
-  #if defined(__i386__) || defined(__arm__)
-    #define __NR__getresgid32 __NR_getresgid32
-    #define __NR__getresuid32 __NR_getresuid32
-    #define __NR__setfsgid32  __NR_setfsgid32
-    #define __NR__setfsuid32  __NR_setfsuid32
-    #define __NR__setgroups32 __NR_setgroups32
-    #define __NR__setgroups   __NR_setgroups
-    #define __NR__setresgid32 __NR_setresgid32
-    #define __NR__setresuid32 __NR_setresuid32
-    LSS_INLINE _syscall2(int,   ugetrlimit,        int,          r,
-                        struct kernel_rlimit*, l)
-    LSS_INLINE _syscall3(int,     _getresgid32,    gid_t *,      r,
-                         gid_t *,            e,    gid_t *,      s)
-    LSS_INLINE _syscall3(int,     _getresuid32,    uid_t *,      r,
-                         uid_t *,            e,    uid_t *,      s)
-    LSS_INLINE _syscall1(int,     _setfsgid32,      gid_t,       f)
-    LSS_INLINE _syscall1(int,     _setfsuid32,      uid_t,       f)
-    LSS_INLINE _syscall2(int,     _setgroups32,     int,         s,
-                         const unsigned int *, l)
-    LSS_INLINE _syscall2(int,     _setgroups,       size_t,      c,
-                         const unsigned short *, g)
-    LSS_INLINE _syscall3(int,     _setresgid32,     gid_t,       r,
-                         gid_t,              e,     gid_t,       s)
-    LSS_INLINE _syscall3(int,     _setresuid32,     uid_t,       r,
-                         uid_t,              e,     uid_t,       s)
-
-    LSS_INLINE int LSS_NAME(getresgid32)(gid_t *rgid,
-                                         gid_t *egid,
-                                         gid_t *sgid) {
-      int rc;
-      if ((rc = LSS_NAME(_getresgid32)(rgid, egid, sgid)) < 0 &&
-          LSS_ERRNO == ENOSYS) {
-        if ((rgid == NULL) || (egid == NULL) || (sgid == NULL)) {
-          return EFAULT;
-        }
-        // Clear the high bits first, since getresgid only sets 16 bits
-        *rgid = *egid = *sgid = 0;
-        rc = LSS_NAME(getresgid)(rgid, egid, sgid);
-      }
-      return rc;
-    }
-
-    LSS_INLINE int LSS_NAME(getresuid32)(uid_t *ruid,
-                                         uid_t *euid,
-                                         uid_t *suid) {
-      int rc;
-      if ((rc = LSS_NAME(_getresuid32)(ruid, euid, suid)) < 0 &&
-          LSS_ERRNO == ENOSYS) {
-        if ((ruid == NULL) || (euid == NULL) || (suid == NULL)) {
-          return EFAULT;
-        }
-        // Clear the high bits first, since getresuid only sets 16 bits
-        *ruid = *euid = *suid = 0;
-        rc = LSS_NAME(getresuid)(ruid, euid, suid);
-      }
-      return rc;
-    }
-
-    LSS_INLINE int LSS_NAME(setfsgid32)(gid_t gid) {
-      int rc;
-      if ((rc = LSS_NAME(_setfsgid32)(gid)) < 0 &&
-          LSS_ERRNO == ENOSYS) {
-        if ((unsigned int)gid & ~0xFFFFu) {
-          LSS_ERRNO = EINVAL;
-        } else {
-          rc = LSS_NAME(setfsgid)(gid);
-        }
-      }
-      return rc;
-    }
-
-    LSS_INLINE int LSS_NAME(setfsuid32)(uid_t uid) {
-      int rc;
-      if ((rc = LSS_NAME(_setfsuid32)(uid)) < 0 &&
-          LSS_ERRNO == ENOSYS) {
-        if ((unsigned int)uid & ~0xFFFFu) {
-          LSS_ERRNO = EINVAL;
-        } else {
-          rc = LSS_NAME(setfsuid)(uid);
-        }
-      }
-      return rc;
-    }
-
-
-    // We cannot allocate memory so there is a problem with building the
-    // list of groups with the proper datatype.  Older kernels have limits
-    // on the number of groups that can be set at one time of up to 32.
-    // So we have an array on the stack of size 32 where to put the groups.
-    #define LSS_SET_GROUPS_SIZE 32
-    LSS_INLINE int LSS_NAME(setgroups)(size_t size, const unsigned int *list) {
-      int rc = 0;
-      if ((rc = LSS_NAME(_setgroups32)(size, list)) < 0 &&
-          LSS_ERRNO == ENOSYS) {
-        if (size > LSS_SET_GROUPS_SIZE) {
-          LSS_ERRNO = EINVAL;
-        } else {
-          unsigned short gid_list[LSS_SET_GROUPS_SIZE];
-          int i;
-          for (i = 0; i < size; ++i) {
-            if (list[i] & ~0xFFFFu) {
-              LSS_ERRNO = EINVAL;
-              break;
-            }
-            gid_list[i] = list[i];
-          }
-          if (LSS_ERRNO != EINVAL) {
-            rc = LSS_NAME(_setgroups)(size, gid_list);
-          }
-        }
-      }
-      return rc;
-    }
-    #undef LSS_SET_GROUPS_SIZE
-
-    LSS_INLINE int LSS_NAME(setresgid32)(gid_t rgid, gid_t egid, gid_t sgid) {
-      int rc;
-      if ((rc = LSS_NAME(_setresgid32)(rgid, egid, sgid)) < 0 &&
-          LSS_ERRNO == ENOSYS) {
-        if ((unsigned int)rgid & ~0xFFFFu ||
-            (unsigned int)egid & ~0xFFFFu ||
-            (unsigned int)sgid & ~0xFFFFu) {
-          LSS_ERRNO = EINVAL;
-        } else {
-          rc = LSS_NAME(setresgid)(rgid, egid, sgid);
-        }
-      }
-      return rc;
-    }
-
-    LSS_INLINE int LSS_NAME(setresuid32)(uid_t ruid, uid_t euid, uid_t suid) {
-      int rc;
-      if ((rc = LSS_NAME(_setresuid32)(ruid, euid, suid)) < 0 &&
-          LSS_ERRNO == ENOSYS) {
-        if ((unsigned int)ruid & ~0xFFFFu ||
-            (unsigned int)euid & ~0xFFFFu ||
-            (unsigned int)suid & ~0xFFFFu) {
-          LSS_ERRNO = EINVAL;
-        } else {
-          rc = LSS_NAME(setresuid)(ruid, euid, suid);
-        }
-      }
-      return rc;
+    LSS_INLINE int LSS_NAME(open)(const char* p, int f, int m) {
+      return LSS_NAME(openat)(AT_FDCWD,p,f,m );
     }
+  #else
+  LSS_INLINE _syscall3(int,     open,            const char*, p,
+                       int,            f, int,    m)
   #endif
   LSS_INLINE int LSS_NAME(sigemptyset)(struct kernel_sigset_t *set) {
     memset(&set->sig, 0, sizeof(set->sig));
@@ -3163,51 +2655,40 @@ struct kernel_io_event {
     }
   }

-  LSS_INLINE int LSS_NAME(sigismember)(struct kernel_sigset_t *set,
-                                          int signum) {
-    if (signum < 1 || signum > (int)(8*sizeof(set->sig))) {
-      LSS_ERRNO = EINVAL;
-      return -1;
-    } else {
-      return !!(set->sig[(signum - 1)/(8*sizeof(set->sig[0]))] &
-                (1UL << ((signum - 1) % (8*sizeof(set->sig[0])))));
-    }
-  }
-  #if defined(__i386__) || \
-      defined(__arm__) || \
-     (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI32) || \
-     (defined(__PPC__) && !defined(__PPC64__))
+  #if defined(__i386__) ||                                                    \
+      defined(__arm__) ||                                                     \
+     (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI32) ||                   \
+      defined(__PPC__) ||                                                     \
+     (defined(__s390__) && !defined(__s390x__))
     #define __NR__sigaction   __NR_sigaction
-    #define __NR__sigpending  __NR_sigpending
     #define __NR__sigprocmask __NR_sigprocmask
-    #define __NR__sigsuspend  __NR_sigsuspend
     LSS_INLINE _syscall2(int, fstat64,             int, f,
                          struct kernel_stat64 *, b)
     LSS_INLINE _syscall5(int, _llseek,     uint, fd, ulong, hi, ulong, lo,
                          loff_t *, res, uint, wh)
-
-    #ifndef __ARM_EABI__
-    /* Not available on ARM EABI Linux.  */
-    LSS_INLINE _syscall1(void*, mmap,              void*, a)
-    #endif
-    LSS_INLINE _syscall6(void*, mmap2,             void*, s,
+#if defined(__s390__) && !defined(__s390x__)
+    /* On s390, mmap2() arguments are passed in memory. */
+    LSS_INLINE void* LSS_NAME(_mmap2)(void *s, size_t l, int p, int f, int d,
+                                      off_t o) {
+      unsigned long buf[6] = { (unsigned long) s, (unsigned long) l,
+                               (unsigned long) p, (unsigned long) f,
+                               (unsigned long) d, (unsigned long) o };
+      LSS_REG(2, buf);
+      LSS_BODY(void*, mmap2, "0"(__r2));
+    }
+#elif !defined(__PPC64__)
+    #define __NR__mmap2 __NR_mmap2
+    LSS_INLINE _syscall6(void*, _mmap2,            void*, s,
                          size_t,                   l, int,               p,
                          int,                      f, int,               d,
                          off_t,                    o)
+#endif
     LSS_INLINE _syscall3(int,   _sigaction,        int,   s,
                          const struct kernel_old_sigaction*,  a,
                          struct kernel_old_sigaction*,        o)
-    LSS_INLINE _syscall1(int,   _sigpending, unsigned long*, s)
     LSS_INLINE _syscall3(int,   _sigprocmask,      int,   h,
                          const unsigned long*,     s,
                          unsigned long*,           o)
-    #ifdef __PPC__
-    LSS_INLINE _syscall1(int, _sigsuspend,         unsigned long, s)
-    #else
-    LSS_INLINE _syscall3(int, _sigsuspend,         const void*, a,
-                         int,                      b,
-                         unsigned long,            s)
-    #endif
     LSS_INLINE _syscall2(int, stat64,              const char *, p,
                          struct kernel_stat64 *, b)

@@ -3273,17 +2754,6 @@ struct kernel_io_event {
       return rc;
     }

-    LSS_INLINE int LSS_NAME(sigpending)(struct kernel_sigset_t *set) {
-      int old_errno = LSS_ERRNO;
-      int rc = LSS_NAME(rt_sigpending)(set, (KERNEL_NSIG+7)/8);
-      if (rc < 0 && LSS_ERRNO == ENOSYS) {
-        LSS_ERRNO = old_errno;
-        LSS_NAME(sigemptyset)(set);
-        rc = LSS_NAME(_sigpending)(&set->sig[0]);
-      }
-      return rc;
-    }
-
     LSS_INLINE int LSS_NAME(sigprocmask)(int how,
                                          const struct kernel_sigset_t *set,
                                          struct kernel_sigset_t *oldset) {
@@ -3300,161 +2770,59 @@ struct kernel_io_event {
       }
       return rc;
     }
-
-    LSS_INLINE int LSS_NAME(sigsuspend)(const struct kernel_sigset_t *set) {
-      int olderrno = LSS_ERRNO;
-      int rc = LSS_NAME(rt_sigsuspend)(set, (KERNEL_NSIG+7)/8);
-      if (rc < 0 && LSS_ERRNO == ENOSYS) {
-        LSS_ERRNO = olderrno;
-        rc = LSS_NAME(_sigsuspend)(
-        #ifndef __PPC__
-                                   set, 0,
-        #endif
-                                   set->sig[0]);
-      }
-      return rc;
-    }
   #endif
-  #if defined(__PPC__)
-    #undef LSS_SC_LOADARGS_0
-    #define LSS_SC_LOADARGS_0(dummy...)
-    /* arg1 .. arg6 are passed in an unsigned long array pointed by r4.  */
-    #undef LSS_SC_LOADARGS_1
-    #define LSS_SC_LOADARGS_1(arg1)                                           \
-        sc_args[0] = (unsigned long) (arg1)
-    #undef LSS_SC_LOADARGS_2
-    #define LSS_SC_LOADARGS_2(arg1, arg2)                                     \
-        LSS_SC_LOADARGS_1(arg1);                                              \
-        sc_args[1] = (unsigned long) (arg2)
-    #undef LSS_SC_LOADARGS_3
-    #define LSS_SC_LOADARGS_3(arg1, arg2, arg3)                               \
-        LSS_SC_LOADARGS_2(arg1, arg2);                                        \
-        sc_args[2] = (unsigned long) (arg3)
-    #undef LSS_SC_LOADARGS_4
-    #define LSS_SC_LOADARGS_4(arg1, arg2, arg3, arg4)                         \
-        LSS_SC_LOADARGS_3(arg1, arg2, arg3);                                  \
-        sc_args[3] = (unsigned long) (arg4)
-    #undef LSS_SC_LOADARGS_5
-    #define LSS_SC_LOADARGS_5(arg1, arg2, arg3, arg4, arg5)                   \
-        LSS_SC_LOADARGS_4(arg1, arg2, arg3, arg4);                            \
-        sc_args[4] = (unsigned long) (arg5)
-    #undef LSS_SC_LOADARGS_6
-    #define LSS_SC_LOADARGS_6(arg1, arg2, arg3, arg4, arg5, arg6)             \
-        LSS_SC_LOADARGS_5(arg1, arg2, arg3, arg4, arg5);                      \
-        sc_args[5] = (unsigned long) (arg6)
-    #undef LSS_SC_BODY
-    /*
-     * Do a socket system call using the generic socketcall() interface.
-     * We pack arguments into an array of unsigned longs and then
-     * call socketcall() with a function number and the argument array.
-     * Although some socket calls now have their own syscall numbers,
-     * we still use socketcall() to make our code work with older kernels.
-     */
-    #define LSS_SC_BODY(nr, type, opt, args...)                               \
-        long __sc_ret, __sc_err;                                              \
-        {                                                                     \
-          unsigned long sc_args[6];                                           \
-          register unsigned long __sc_0 __asm__ ("r0") = __NR_socketcall;     \
-          register unsigned long __sc_3 __asm__ ("r3") = opt;                 \
-          register unsigned long __sc_4 __asm__ ("r4");                       \
-          LSS_SC_LOADARGS_##nr(args);                                         \
-          __asm__ __volatile__                                                \
-              ("sc\n\t"                                                       \
-               "mfcr %0"                                                      \
-                 : "+r" (__sc_0),                                             \
-                   "+r" (__sc_3), "=r" (__sc_4)                               \
-                 : "2"(&sc_args)                                              \
-                 : "r5", "r6", "r7", "r8", "r9", "r10", "r11", "r12",         \
-                   "cr0", "ctr", "memory");                                   \
-          __sc_ret = __sc_3;                                                  \
-          __sc_err = __sc_0;                                                  \
-        }                                                                     \
-        LSS_RETURN(type, __sc_ret, __sc_err)
-
-    LSS_INLINE ssize_t LSS_NAME(recvmsg)(int s,struct kernel_msghdr *msg,
-                                         int flags){
-      LSS_SC_BODY(3, ssize_t, 17, s, msg, flags);
-    }
-
-    LSS_INLINE ssize_t LSS_NAME(sendmsg)(int s,
-                                         const struct kernel_msghdr *msg,
-                                         int flags) {
-      LSS_SC_BODY(3, ssize_t, 16, s, msg, flags);
-    }
-
-    LSS_INLINE ssize_t LSS_NAME(sendto)(int s, const void *buf, size_t len,
-                                        int flags,
-                                        const struct kernel_sockaddr *to,
-                                        unsigned int tolen) {
-      LSS_SC_BODY(6, ssize_t, 11, s, buf, len, flags, to, tolen);
-    }
-
-    LSS_INLINE int LSS_NAME(shutdown)(int s, int how) {
-      LSS_SC_BODY(2, int, 13, s, how);
+  #if defined(__i386__) ||                                                    \
+      defined(__ARM_ARCH_3__) || defined(__ARM_EABI__) ||                     \
+     (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI32) ||                   \
+     (defined(__PPC__) && !defined(__PPC64__)) ||                             \
+     (defined(__s390__) && !defined(__s390x__))
+    /* On these architectures, implement mmap() with mmap2(). */
+    LSS_INLINE void* LSS_NAME(mmap)(void *s, size_t l, int p, int f, int d,
+                                    int64_t o) {
+      if (o % 4096) {
+        LSS_ERRNO = EINVAL;
+        return (void *) -1;
+      }
+      return LSS_NAME(_mmap2)(s, l, p, f, d, (o / 4096));
     }
-
-    LSS_INLINE int LSS_NAME(socket)(int domain, int type, int protocol) {
-      LSS_SC_BODY(3, int, 1, domain, type, protocol);
+  #elif defined(__s390x__)
+    /* On s390x, mmap() arguments are passed in memory. */
+    LSS_INLINE void* LSS_NAME(mmap)(void *s, size_t l, int p, int f, int d,
+                                    int64_t o) {
+      unsigned long buf[6] = { (unsigned long) s, (unsigned long) l,
+                               (unsigned long) p, (unsigned long) f,
+                               (unsigned long) d, (unsigned long) o };
+      LSS_REG(2, buf);
+      LSS_BODY(void*, mmap, "0"(__r2));
     }
-
-    LSS_INLINE int LSS_NAME(socketpair)(int d, int type, int protocol,
-                                        int sv[2]) {
-      LSS_SC_BODY(4, int, 8, d, type, protocol, sv);
+  #elif defined(__x86_64__)
+    /* Need to make sure __off64_t isn't truncated to 32-bits under x32.  */
+    LSS_INLINE void* LSS_NAME(mmap)(void *s, size_t l, int p, int f, int d,
+                                    int64_t o) {
+      LSS_BODY(6, void*, mmap, LSS_SYSCALL_ARG(s), LSS_SYSCALL_ARG(l),
+                               LSS_SYSCALL_ARG(p), LSS_SYSCALL_ARG(f),
+                               LSS_SYSCALL_ARG(d), (uint64_t)(o));
     }
+  #elif defined(__aarch64__) && defined (__ILP32__)
+    /* aarch64_ilp32 uses mmap2 for sys_mmap() */
+    LSS_INLINE _syscall6_long(void*, mmap, mmap2, void*, addr, size_t, length,
+                              int, prot, int, flags, int, fd, int64_t, offset)
+  #else
+    /* Remaining 64-bit architectures. */
+    LSS_INLINE _syscall6(void*, mmap, void*, addr, size_t, length, int, prot,
+                         int, flags, int, fd, int64_t, offset)
   #endif
   #if defined(__i386__) || \
+      defined(__PPC__) || \
       (defined(__arm__) && !defined(__ARM_EABI__)) || \
-      (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI32)
+      (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI32) || \
+      defined(__s390__)

     /* See sys_socketcall in net/socket.c in kernel source.
      * It de-multiplexes on its first arg and unpacks the arglist
      * array in its second arg.
      */
-    LSS_INLINE _syscall2(long, socketcall, int, c, unsigned long*, a)
-
-    LSS_INLINE ssize_t LSS_NAME(recvmsg)(int s,struct kernel_msghdr *msg,
-                                         int flags){
-      unsigned long args[3] = {
-        (unsigned long) s,
-        (unsigned long) msg,
-        (unsigned long) flags
-      };
-      return (ssize_t) LSS_NAME(socketcall)(17, args);
-    }
-
-    LSS_INLINE ssize_t LSS_NAME(sendmsg)(int s,
-                                         const struct kernel_msghdr *msg,
-                                         int flags) {
-      unsigned long args[3] = {
-        (unsigned long) s,
-        (unsigned long) msg,
-        (unsigned long) flags
-      };
-      return (ssize_t) LSS_NAME(socketcall)(16, args);
-    }
-
-    LSS_INLINE ssize_t LSS_NAME(sendto)(int s, const void *buf, size_t len,
-                                        int flags,
-                                        const struct kernel_sockaddr *to,
-                                        unsigned int tolen) {
-      unsigned long args[6] = {
-        (unsigned long) s,
-        (unsigned long) buf,
-        (unsigned long) len,
-        (unsigned long) flags,
-        (unsigned long) to,
-        (unsigned long) tolen
-      };
-      return (ssize_t) LSS_NAME(socketcall)(11, args);
-    }
-
-    LSS_INLINE int LSS_NAME(shutdown)(int s, int how) {
-      unsigned long args[2] = {
-        (unsigned long) s,
-        (unsigned long) how
-      };
-      return LSS_NAME(socketcall)(13, args);
-    }
+    LSS_INLINE _syscall2(int, socketcall, int, c, unsigned long*, a)

     LSS_INLINE int LSS_NAME(socket)(int domain, int type, int protocol) {
       unsigned long args[3] = {
@@ -3464,45 +2832,9 @@ struct kernel_io_event {
       };
       return LSS_NAME(socketcall)(1, args);
     }
-
-    LSS_INLINE int LSS_NAME(socketpair)(int d, int type, int protocol,
-                                        int sv[2]) {
-      unsigned long args[4] = {
-        (unsigned long) d,
-        (unsigned long) type,
-        (unsigned long) protocol,
-        (unsigned long) sv
-      };
-      return LSS_NAME(socketcall)(8, args);
-    }
   #elif defined(__ARM_EABI__)
-    /* ARM EABI Linix does not have socketcall.  */
-    LSS_INLINE _syscall3(ssize_t, recvmsg,             int,   s,
-                         struct kernel_msghdr*,     m, int, f)
-    LSS_INLINE _syscall3(ssize_t, sendmsg,            int,   s,
-                         const struct kernel_msghdr*, m, int, f)
-    LSS_INLINE _syscall6(ssize_t, sendto,         int,   s,
-                         const void*,             b, size_t, l,
-                         int,                     f,
-                         const struct kernel_sockaddr*, to,
-                         unsigned int,            tl)
-    LSS_INLINE _syscall2(int, shutdown,           int,   s,
-                         int,                     h)
     LSS_INLINE _syscall3(int, socket,             int,   d,
                          int,                     t, int,       p)
-    LSS_INLINE _syscall4(int, socketpair,         int,   d,
-                         int,                     t, int,       p, int*, s)
-  #endif
-  #if defined(__i386__) || (defined(__PPC__) && !defined(__PPC64__)) || \
-      defined(__arm__)
-    LSS_INLINE _syscall4(int,   fstatat64,        int,   d,
-                         const char *,      p,
-                         struct kernel_stat64 *,   b,    int,   f)
-  #endif
-  #if defined(__i386__) || defined(__PPC__) ||                                \
-     (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI32)
-    LSS_INLINE _syscall3(pid_t, waitpid,          pid_t, p,
-                         int*,              s,    int,   o)
   #endif
   #if defined(__mips__)
     /* sys_pipe() on MIPS has non-standard calling conventions, as it returns
@@ -3526,32 +2858,15 @@ struct kernel_io_event {
         return 0;
       }
     }
+  #elif defined(__NR_pipe2)
+    LSS_INLINE _syscall2(int,     pipe2,          int *, p,
+                         int,     f                        )
+    LSS_INLINE int LSS_NAME(pipe)( int * p) {
+        return LSS_NAME(pipe2)(p, 0);
+    }
   #else
     LSS_INLINE _syscall1(int,     pipe,           int *, p)
   #endif
-  /* TODO(user): see if ppc can/should support this as well              */
-  #if defined(__i386__) || \
-      defined(__arm__) || \
-     (defined(__mips__) && _MIPS_SIM != _MIPS_SIM_ABI64)
-    #define __NR__statfs64  __NR_statfs64
-    #define __NR__fstatfs64 __NR_fstatfs64
-    LSS_INLINE _syscall3(int, _statfs64,     const char*, p,
-                         size_t, s,struct kernel_statfs64*, b)
-    LSS_INLINE _syscall3(int, _fstatfs64,          int,   f,
-                         size_t, s,struct kernel_statfs64*, b)
-    LSS_INLINE int LSS_NAME(statfs64)(const char *p,
-                                     struct kernel_statfs64 *b) {
-      return LSS_NAME(_statfs64)(p, sizeof(*b), b);
-    }
-    LSS_INLINE int LSS_NAME(fstatfs64)(int f,struct kernel_statfs64 *b) {
-      return LSS_NAME(_fstatfs64)(f, sizeof(*b), b);
-    }
-  #endif
-
-  LSS_INLINE int LSS_NAME(execv)(const char *path, const char *const argv[]) {
-    extern char **environ;
-    return LSS_NAME(execve)(path, argv, (const char *const *)environ);
-  }

   LSS_INLINE pid_t LSS_NAME(gettid)() {
     pid_t tid = LSS_NAME(_gettid)();
@@ -3574,102 +2889,20 @@ struct kernel_io_event {
   }

   LSS_INLINE int LSS_NAME(ptrace_detach)(pid_t pid) {
-    return LSS_NAME(ptrace)(PTRACE_DETACH, pid, (void *)0, (void *)0);
-  }
-
-  LSS_INLINE int LSS_NAME(raise)(int sig) {
-    return LSS_NAME(kill)(LSS_NAME(getpid)(), sig);
-  }
-
-  LSS_INLINE int LSS_NAME(setpgrp)() {
-    return LSS_NAME(setpgid)(0, 0);
-  }
-
-  LSS_INLINE int LSS_NAME(sysconf)(int name) {
-    extern int __getpagesize(void);
-    switch (name) {
-      case _SC_OPEN_MAX: {
-        struct kernel_rlimit limit;
-
-        /* On some systems getrlimit is obsolete, use ugetrlimit instead. */
-  #ifndef __NR_getrlimit
-        return LSS_NAME(ugetrlimit)(RLIMIT_NOFILE, &limit) < 0
-               ? 8192 : limit.rlim_cur;
-  #else
-        return LSS_NAME(getrlimit)(RLIMIT_NOFILE, &limit) < 0
-               ? 8192 : limit.rlim_cur;
-  #endif
-      }
-      case _SC_PAGESIZE:
-        return __getpagesize();
-      default:
-        LSS_ERRNO = ENOSYS;
-        return -1;
-    }
-  }
-  #if defined(__x86_64__) ||                                                  \
-     (defined(__mips__) && _MIPS_SIM == _MIPS_SIM_ABI64)
-    LSS_INLINE _syscall4(ssize_t, pread64,        int,         f,
-                         void *,         b, size_t,   c,
-                         loff_t,         o)
-    LSS_INLINE _syscall4(ssize_t, pwrite64,       int,         f,
-                         const void *,   b, size_t,   c,
-                         loff_t,         o)
-    LSS_INLINE _syscall3(int,     readahead,      int,         f,
-                         loff_t,         o, unsigned, c)
-  #else
-    #define __NR__pread64   __NR_pread64
-    #define __NR__pwrite64  __NR_pwrite64
-    #define __NR__readahead __NR_readahead
-    LSS_INLINE _syscall5(ssize_t, _pread64,        int,         f,
-                         void *,         b, size_t, c, unsigned, o1,
-                         unsigned, o2)
-    LSS_INLINE _syscall5(ssize_t, _pwrite64,       int,         f,
-                         const void *,   b, size_t, c, unsigned, o1,
-                         long, o2)
-    LSS_INLINE _syscall4(int, _readahead,          int,         f,
-                         unsigned,       o1, unsigned, o2, size_t, c);
-    /* We force 64bit-wide parameters onto the stack, then access each
-     * 32-bit component individually. This guarantees that we build the
-     * correct parameters independent of the native byte-order of the
-     * underlying architecture.
+    /* PTRACE_DETACH can sometimes forget to wake up the tracee and it
+     * then sends job control signals to the real parent, rather than to
+     * the tracer. We reduce the risk of this happening by starting a
+     * whole new time slice, and then quickly sending a SIGCONT signal
+     * right after detaching from the tracee.
      */
-    LSS_INLINE ssize_t LSS_NAME(pread64)(int fd, void *buf, size_t count,
-                                         loff_t off) {
-      union { loff_t off; unsigned arg[2]; } o = { off };
-      return LSS_NAME(_pread64)(fd, buf, count, o.arg[0], o.arg[1]);
-    }
-    LSS_INLINE ssize_t LSS_NAME(pwrite64)(int fd, const void *buf,
-                                          size_t count, loff_t off) {
-      union { loff_t off; unsigned arg[2]; } o = { off };
-      return LSS_NAME(_pwrite64)(fd, buf, count, o.arg[0], o.arg[1]);
-    }
-    LSS_INLINE int LSS_NAME(readahead)(int fd, loff_t off, int len) {
-      union { loff_t off; unsigned arg[2]; } o = { off };
-      return LSS_NAME(_readahead)(fd, o.arg[0], o.arg[1], len);
-    }
-  #endif
-  #if defined(__NR_io_setup)
-    LSS_INLINE _syscall2(int, io_setup,
-                         int,                     maxevents,
-                         unsigned long *,         ctxp);
-    LSS_INLINE _syscall3(int, io_submit,
-                         unsigned long,           ctx_id,
-                         long,                    nr,
-                         struct kernel_iocb **,   ios);
-    LSS_INLINE _syscall5(int, io_getevents,
-                         unsigned long,            ctx_id,
-                         long,                     min_nr,
-                         long,                     nr,
-                         struct kernel_io_event *, events,
-                         struct kernel_timespec*,  timeout);
-    LSS_INLINE _syscall1(int, io_destroy,
-                         unsigned long,            ctx);
-    LSS_INLINE _syscall3(int, io_cancel,
-                         unsigned long,            ctx_id,
-                         struct kernel_iocb*,      iocb,
-                         struct kernel_io_event*,  result);
-  #endif
+    int rc, err;
+    LSS_NAME(sched_yield)();
+    rc = LSS_NAME(ptrace)(PTRACE_DETACH, pid, (void *)0, (void *)0);
+    err = LSS_ERRNO;
+    LSS_NAME(kill)(pid, SIGCONT);
+    LSS_ERRNO = err;
+    return rc;
+  }
 #endif

 #if defined(__cplusplus) && !defined(SYS_CPLUSPLUS)
diff --git a/src/kudu/gutil/cpu.cc b/src/kudu/gutil/cpu.cc
index 17063a04c..cfad13771 100644
--- a/src/kudu/gutil/cpu.cc
+++ b/src/kudu/gutil/cpu.cc
@@ -266,6 +266,9 @@ void CPU::Initialize() {
 #elif defined(ARCH_CPU_ARM_FAMILY) && (defined(OS_ANDROID) || defined(OS_LINUX))
   cpu_brand_.assign(g_lazy_cpuinfo.Get().brand());
   has_broken_neon_ = g_lazy_cpuinfo.Get().has_broken_neon();
+#elif defined(__aarch64__)
+  cpu_brand_.assign("ARM64");
+  has_broken_neon_ = false;
 #else
   #error unknown architecture
 #endif
diff --git a/src/kudu/gutil/spinlock.h b/src/kudu/gutil/spinlock.h
index eced3ef12..01fd22e6f 100644
--- a/src/kudu/gutil/spinlock.h
+++ b/src/kudu/gutil/spinlock.h
@@ -76,6 +76,7 @@ class LOCKABLE SpinLock {
       SlowLock();
     }
     ANNOTATE_RWLOCK_ACQUIRED(this, 1);
+    __asm__ __volatile__ ("dmb ish" ::: "memory");
   }

   // Try to acquire this SpinLock without blocking and return true if the
@@ -89,6 +90,7 @@ class LOCKABLE SpinLock {
     if (res) {
       ANNOTATE_RWLOCK_ACQUIRED(this, 1);
     }
+    __asm__ __volatile__ ("dmb ish" ::: "memory");
     return res;
   }

@@ -105,6 +107,7 @@ class LOCKABLE SpinLock {
       // for the lock.
       SlowUnlock(wait_cycles);
     }
+    __asm__ __volatile__ ("dmb ish" ::: "memory");
   }

   // Determine if the lock is held.  When the lock is held by the invoking
diff --git a/src/kudu/gutil/atomicops.h b/src/kudu/gutil/atomicops.h
index c29a02f4e..2f09521da 100644
--- a/src/kudu/gutil/atomicops.h
+++ b/src/kudu/gutil/atomicops.h
@@ -84,6 +84,8 @@
 #include "kudu/gutil/atomicops-internals-powerpc.h" // IWYU pragma: export
 #elif defined(OS_WINDOWS)
 #include "kudu/gutil/atomicops-internals-windows.h" // IWYU pragma: export
+#elif defined(__GNUC__) && defined(__aarch64__)
+#include "kudu/gutil/atomicops-internals-arm64.h" // IWYU pragma: export
 #else
 #error You need to implement atomic operations for this architecture
 #endif
diff --git a/src/kudu/gutil/atomicops-internals-arm64.h b/src/kudu/gutil/atomicops-internals-arm64.h
new file mode 100644
index 000000000..eefaf5d84
--- /dev/null
+++ b/src/kudu/gutil/atomicops-internals-arm64.h
@@ -0,0 +1,356 @@
+// Protocol Buffers - Google's data interchange format
+// Copyright 2012 Google Inc.  All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are
+// met:
+//
+//     * Redistributions of source code must retain the above copyright
+// notice, this list of conditions and the following disclaimer.
+//     * Redistributions in binary form must reproduce the above
+// copyright notice, this list of conditions and the following disclaimer
+// in the documentation and/or other materials provided with the
+// distribution.
+//     * Neither the name of Google Inc. nor the names of its
+// contributors may be used to endorse or promote products derived from
+// this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+// This file is an internal atomic implementation, use atomicops.h instead.
+
+#ifndef GUTIL_ATOMICOPS_INTERNALS_ARM64_H_
+#define GUTIL_ATOMICOPS_INTERNALS_ARM64_H_
+
+typedef int32_t Atomic32;
+typedef int64_t Atomic64;
+
+namespace base {
+namespace subtle {
+
+typedef int32_t Atomic32;
+typedef int64_t Atomic64;
+
+inline void MemoryBarrier() {
+  __asm__ __volatile__ ("dmb ish" ::: "memory");  // NOLINT
+}
+// NoBarrier versions of the operation include "memory" in the clobber list.
+// This is not required for direct usage of the NoBarrier versions of the
+// operations. However this is required for correctness when they are used as
+// part of the Acquire or Release versions, to ensure that nothing from outside
+// the call is reordered between the operation and the memory barrier. This does
+// not change the code generated, so has no or minimal impact on the
+// NoBarrier operations.
+
+inline Atomic32 NoBarrier_CompareAndSwap(volatile Atomic32* ptr,
+                                         Atomic32 old_value,
+                                         Atomic32 new_value) {
+  Atomic32 prev;
+  int32_t temp;
+
+  __asm__ __volatile__ (  // NOLINT
+    "0:                                    \n\t"
+    "ldxr %w[prev], %[ptr]                 \n\t"  // Load the previous value.
+    "cmp %w[prev], %w[old_value]           \n\t"
+    "bne 1f                                \n\t"
+    "stxr %w[temp], %w[new_value], %[ptr]  \n\t"  // Try to store the new value.
+    "cbnz %w[temp], 0b                     \n\t"  // Retry if it did not work.
+    "1:                                    \n\t"
+    : [prev]"=&r" (prev),
+      [temp]"=&r" (temp),
+      [ptr]"+Q" (*ptr)
+    : [old_value]"IJr" (old_value),
+      [new_value]"r" (new_value)
+    : "cc", "memory"
+  );  // NOLINT
+
+  return prev;
+}
+
+inline Atomic32 NoBarrier_AtomicExchange(volatile Atomic32* ptr,
+                                         Atomic32 new_value) {
+  Atomic32 result;
+  int32_t temp;
+
+  __asm__ __volatile__ (  // NOLINT
+    "0:                                    \n\t"
+    "ldxr %w[result], %[ptr]               \n\t"  // Load the previous value.
+    "stxr %w[temp], %w[new_value], %[ptr]  \n\t"  // Try to store the new value.
+    "cbnz %w[temp], 0b                     \n\t"  // Retry if it did not work.
+    : [result]"=&r" (result),
+      [temp]"=&r" (temp),
+      [ptr]"+Q" (*ptr)
+    : [new_value]"r" (new_value)
+    : "memory"
+  );  // NOLINT
+
+  return result;
+}
+
+inline Atomic32 Acquire_AtomicExchange(volatile Atomic32* ptr,
+                                       Atomic32 new_value) {
+  Atomic32 old_val = NoBarrier_AtomicExchange(ptr, new_value);
+  return old_val;
+}
+
+inline Atomic32 Release_AtomicExchange(volatile Atomic32* ptr,
+                                       Atomic32 new_value) {
+  return NoBarrier_AtomicExchange(ptr, new_value);
+}
+
+inline Atomic32 NoBarrier_AtomicIncrement(volatile Atomic32* ptr,
+                                          Atomic32 increment) {
+  Atomic32 result;
+  int32_t temp;
+
+  __asm__ __volatile__ (  // NOLINT
+    "0:                                       \n\t"
+    "ldxr %w[result], %[ptr]                  \n\t"  // Load the previous value.
+    "add %w[result], %w[result], %w[increment]\n\t"
+    "stxr %w[temp], %w[result], %[ptr]        \n\t"  // Try to store the result.
+    "cbnz %w[temp], 0b                        \n\t"  // Retry on failure.
+    : [result]"=&r" (result),
+      [temp]"=&r" (temp),
+      [ptr]"+Q" (*ptr)
+    : [increment]"IJr" (increment)
+    : "memory"
+  );  // NOLINT
+
+  return result;
+}
+
+inline Atomic32 Barrier_AtomicIncrement(volatile Atomic32* ptr,
+                                        Atomic32 increment) {
+  MemoryBarrier();
+  Atomic32 result = NoBarrier_AtomicIncrement(ptr, increment);
+  MemoryBarrier();
+
+  return result;
+}
+
+inline Atomic32 Acquire_CompareAndSwap(volatile Atomic32* ptr,
+                                       Atomic32 old_value,
+                                       Atomic32 new_value) {
+  Atomic32 prev = NoBarrier_CompareAndSwap(ptr, old_value, new_value);
+  MemoryBarrier();
+  return prev;
+}
+
+inline Atomic32 Release_CompareAndSwap(volatile Atomic32* ptr,
+                                       Atomic32 old_value,
+                                       Atomic32 new_value) {
+  MemoryBarrier();
+  Atomic32 prev = NoBarrier_CompareAndSwap(ptr, old_value, new_value);
+  return prev;
+}
+
+inline void NoBarrier_Store(volatile Atomic32* ptr, Atomic32 value) {
+  *ptr = value;
+  MemoryBarrier();
+}
+
+inline void Acquire_Store(volatile Atomic32* ptr, Atomic32 value) {
+  *ptr = value;
+  MemoryBarrier();
+}
+
+inline void Release_Store(volatile Atomic32* ptr, Atomic32 value) {
+  __asm__ __volatile__ (  // NOLINT
+    "stlr %w[value], %[ptr]  \n\t"
+    : [ptr]"=Q" (*ptr)
+    : [value]"r" (value)
+    : "memory"
+  );  // NOLINT
+}
+
+inline Atomic32 NoBarrier_Load(volatile const Atomic32* ptr) {
+  MemoryBarrier();
+  return *ptr;
+}
+
+inline Atomic32 Acquire_Load(volatile const Atomic32* ptr) {
+  Atomic32 value;
+
+  __asm__ __volatile__ (  // NOLINT
+    "ldar %w[value], %[ptr]  \n\t"
+    : [value]"=r" (value)
+    : [ptr]"Q" (*ptr)
+    : "memory"
+  );  // NOLINT
+
+  return value;
+}
+
+inline Atomic32 Release_Load(volatile const Atomic32* ptr) {
+  MemoryBarrier();
+  return *ptr;
+}
+
+// 64-bit versions of the operations.
+// See the 32-bit versions for comments.
+
+inline Atomic64 NoBarrier_CompareAndSwap(volatile Atomic64* ptr,
+                                         Atomic64 old_value,
+                                         Atomic64 new_value) {
+  Atomic64 prev;
+  int32_t temp;
+
+  __asm__ __volatile__ (  // NOLINT
+    "0:                                    \n\t"
+    "ldxr %[prev], %[ptr]                  \n\t"
+    "cmp %[prev], %[old_value]             \n\t"
+    "bne 1f                                \n\t"
+    "stxr %w[temp], %[new_value], %[ptr]   \n\t"
+    "cbnz %w[temp], 0b                     \n\t"
+    "1:                                    \n\t"
+    : [prev]"=&r" (prev),
+      [temp]"=&r" (temp),
+      [ptr]"+Q" (*ptr)
+    : [old_value]"IJr" (old_value),
+      [new_value]"r" (new_value)
+    : "cc", "memory"
+  );  // NOLINT
+
+  return prev;
+}
+
+inline Atomic64 NoBarrier_AtomicExchange(volatile Atomic64* ptr,
+                                         Atomic64 new_value) {
+  Atomic64 result;
+  int32_t temp;
+
+  __asm__ __volatile__ (  // NOLINT
+    "0:                                    \n\t"
+    "ldxr %[result], %[ptr]                \n\t"
+    "stxr %w[temp], %[new_value], %[ptr]   \n\t"
+    "cbnz %w[temp], 0b                     \n\t"
+    : [result]"=&r" (result),
+      [temp]"=&r" (temp),
+      [ptr]"+Q" (*ptr)
+    : [new_value]"r" (new_value)
+    : "memory"
+  );  // NOLINT
+
+  return result;
+}
+
+inline void PauseCPU() {
+  __asm__ __volatile__("yield" : : : "memory");
+}
+
+inline Atomic64 Acquire_AtomicExchange(volatile Atomic64* ptr,
+                                       Atomic64 new_value) {
+  Atomic64 old_val = NoBarrier_AtomicExchange(ptr, new_value);
+  return old_val;
+}
+
+inline Atomic64 Release_AtomicExchange(volatile Atomic64* ptr,
+                                       Atomic64 new_value) {
+  return NoBarrier_AtomicExchange(ptr, new_value);
+}
+
+inline Atomic64 NoBarrier_AtomicIncrement(volatile Atomic64* ptr,
+                                          Atomic64 increment) {
+  Atomic64 result;
+  int32_t temp;
+
+  __asm__ __volatile__ (  // NOLINT
+    "0:                                     \n\t"
+    "ldxr %[result], %[ptr]                 \n\t"
+    "add %[result], %[result], %[increment] \n\t"
+    "stxr %w[temp], %[result], %[ptr]       \n\t"
+    "cbnz %w[temp], 0b                      \n\t"
+    : [result]"=&r" (result),
+      [temp]"=&r" (temp),
+      [ptr]"+Q" (*ptr)
+    : [increment]"IJr" (increment)
+    : "memory"
+  );  // NOLINT
+
+  return result;
+}
+
+inline Atomic64 Barrier_AtomicIncrement(volatile Atomic64* ptr,
+                                        Atomic64 increment) {
+  MemoryBarrier();
+  Atomic64 result = NoBarrier_AtomicIncrement(ptr, increment);
+  MemoryBarrier();
+
+  return result;
+}
+
+inline Atomic64 Acquire_CompareAndSwap(volatile Atomic64* ptr,
+                                       Atomic64 old_value,
+                                       Atomic64 new_value) {
+  Atomic64 prev = NoBarrier_CompareAndSwap(ptr, old_value, new_value);
+  MemoryBarrier();
+
+  return prev;
+}
+
+inline Atomic64 Release_CompareAndSwap(volatile Atomic64* ptr,
+                                       Atomic64 old_value,
+                                       Atomic64 new_value) {
+  MemoryBarrier();
+  Atomic64 prev = NoBarrier_CompareAndSwap(ptr, old_value, new_value);
+
+  return prev;
+}
+
+inline void NoBarrier_Store(volatile Atomic64* ptr, Atomic64 value) {
+  *ptr = value;
+  MemoryBarrier();
+}
+
+inline void Acquire_Store(volatile Atomic64* ptr, Atomic64 value) {
+  *ptr = value;
+  MemoryBarrier();
+}
+
+inline void Release_Store(volatile Atomic64* ptr, Atomic64 value) {
+  __asm__ __volatile__ (  // NOLINT
+    "stlr %x[value], %[ptr]  \n\t"
+    : [ptr]"=Q" (*ptr)
+    : [value]"r" (value)
+    : "memory"
+  );  // NOLINT
+}
+
+inline Atomic64 NoBarrier_Load(volatile const Atomic64* ptr) {
+  MemoryBarrier();
+  return *ptr;
+}
+
+inline Atomic64 Acquire_Load(volatile const Atomic64* ptr) {
+  Atomic64 value;
+
+  __asm__ __volatile__ (  // NOLINT
+    "ldar %x[value], %[ptr]  \n\t"
+    : [value]"=r" (value)
+    : [ptr]"Q" (*ptr)
+    : "memory"
+  );  // NOLINT
+
+  return value;
+}
+
+inline Atomic64 Release_Load(volatile const Atomic64* ptr) {
+  MemoryBarrier();
+  return *ptr;
+}
+
+}  // namespace subtle
+}  // namespace base
+
+#endif  // GUTIL_ATOMICOPS_INTERNALS_ARM64_GCC_H_
+
diff --git a/src/kudu/util/debug-util.cc b/src/kudu/util/debug-util.cc
index 03556d607..f8cd4ed79 100644
--- a/src/kudu/util/debug-util.cc
+++ b/src/kudu/util/debug-util.cc
@@ -163,6 +163,8 @@ class CompletionFlag {
     sys_futex(reinterpret_cast<int32_t*>(&complete_),
               FUTEX_WAKE | FUTEX_PRIVATE_FLAG,
               INT_MAX, // wake all
+              NULL,
+              NULL,
               0 /* ignored */);
 #endif
   }
@@ -181,7 +183,9 @@ class CompletionFlag {
       sys_futex(reinterpret_cast<int32_t*>(&complete_),
                 FUTEX_WAIT | FUTEX_PRIVATE_FLAG,
                 0, // wait if value is still 0
-                reinterpret_cast<struct kernel_timespec *>(&ts));
+                reinterpret_cast<struct kernel_timespec *>(&ts),
+                NULL,
+                0);
 #else
       sched_yield();
 #endif
diff --git a/src/kudu/util/debug-util.h b/src/kudu/util/debug-util.h
index e8c94eafd..db4e8d1d0 100644
--- a/src/kudu/util/debug-util.h
+++ b/src/kudu/util/debug-util.h
@@ -31,6 +31,10 @@
 #include "kudu/gutil/strings/fastmem.h"
 #include "kudu/util/status.h"

+#define FUTEX_WAIT 0
+#define FUTEX_WAKE 1
+#define FUTEX_PRIVATE_FLAG 128
+
 namespace kudu {

 template <typename T> class ArrayView;
diff --git a/src/kudu/util/striped64.cc b/src/kudu/util/striped64.cc
index 789a3959f..b77a042cf 100644
--- a/src/kudu/util/striped64.cc
+++ b/src/kudu/util/striped64.cc
@@ -17,7 +17,13 @@

 #include "kudu/util/striped64.h"

+#if defined(__aarch64__)
+#define _mm_free(p) free(p)
+#define _mm_malloc(a, b) malloc(a)
+#else
 #include <mm_malloc.h>
+#endif
+
 #include <unistd.h>

 #include <cstdlib>
diff --git a/src/kudu/util/memory/memory.cc b/src/kudu/util/memory/memory.cc
index b3964dfa6..ed142f574 100644
--- a/src/kudu/util/memory/memory.cc
+++ b/src/kudu/util/memory/memory.cc
@@ -20,7 +20,12 @@

 #include "kudu/util/memory/memory.h"

+#if defined(__aarch64__)
+#define _mm_free(p) free(p)
+#define _mm_malloc(a, b) malloc(a)
+#else
 #include <mm_malloc.h>
+#endif

 #include <algorithm>
 #include <cstdlib>
diff --git a/src/kudu/util/group_varint-inl.h b/src/kudu/util/group_varint-inl.h
index 27e289f83..7d21d88bc 100644
--- a/src/kudu/util/group_varint-inl.h
+++ b/src/kudu/util/group_varint-inl.h
@@ -17,13 +17,16 @@
 #ifndef KUDU_UTIL_GROUP_VARINT_INL_H
 #define KUDU_UTIL_GROUP_VARINT_INL_H

-#include <emmintrin.h>
 #ifdef __linux__
 #include <endian.h>
 #endif
+
+#if !defined(__aarch64__)
+#include <emmintrin.h>
 #include <smmintrin.h>
 #include <tmmintrin.h>
 #include <xmmintrin.h>
+#endif //!__aarch64__

 #include <cstdint>
 #include <cstring>
@@ -122,7 +125,7 @@ inline const uint8_t *DecodeGroupVarInt32_SlowButSafe(
   return src + total_len;
 }

-
+#if !defined(__aarch64__)
 inline void DoExtractM128(__m128i results,
                           uint32_t *a, uint32_t *b, uint32_t *c, uint32_t *d) {
 #define SSE_USE_EXTRACT_PS
@@ -201,7 +204,7 @@ inline const uint8_t *DecodeGroupVarInt32_SSE_Add(
   src += VARINT_SELECTOR_LENGTHS[sel_byte];
   return src;
 }
-
+#endif //!__aarch64__

 // Append a set of group-varint encoded integers to the given faststring.
 inline void AppendGroupVarInt32(
diff --git a/src/kudu/common/key_encoder.h b/src/kudu/common/key_encoder.h
index 92b9bac19..ba0f08966 100644
--- a/src/kudu/common/key_encoder.h
+++ b/src/kudu/common/key_encoder.h
@@ -18,8 +18,10 @@
 #ifndef KUDU_COMMON_KEYENCODER_H
 #define KUDU_COMMON_KEYENCODER_H

+#if !defined(__aarch64__)
 #include <emmintrin.h>
 #include <smmintrin.h>
+#endif

 #include <climits>
 #include <cstdint>
@@ -249,6 +251,7 @@ struct KeyEncoderTraits<BINARY, Buffer> {
   // REQUIRES: len == 16 or 8
   template<int LEN>
   static bool SSEEncodeChunk(const uint8_t** srcp, uint8_t** dstp) {
+    #if !defined(__aarch64__)
     COMPILE_ASSERT(LEN == 16 || LEN == 8, invalid_length);
     __m128i data;
     if (LEN == 16) {
@@ -284,6 +287,7 @@ struct KeyEncoderTraits<BINARY, Buffer> {
     }
     *dstp += LEN;
     *srcp += LEN;
+  #endif
     return true;
   }

diff --git a/src/kudu/cfile/binary_plain_block.cc b/src/kudu/cfile/binary_plain_block.cc
index d8b5e686a..b16903623 100644
--- a/src/kudu/cfile/binary_plain_block.cc
+++ b/src/kudu/cfile/binary_plain_block.cc
@@ -199,9 +199,10 @@ Status BinaryPlainBlockDecoder::ParseHeader() {
   size_t rem = num_elems_;
   while (rem >= 4) {
     if (PREDICT_TRUE(p + 16 < limit)) {
+      #if !defined(__aarch64__)
       p = coding::DecodeGroupVarInt32_SSE(
           p, &dst_ptr[0], &dst_ptr[1], &dst_ptr[2], &dst_ptr[3]);
-
+      #endif
       // The above function should add at most 17 (4 32-bit ints plus a selector byte) to
       // 'p'. Thus, since we checked that (p + 16 < limit) above, we are guaranteed that
       // (p <= limit) now.
diff --git a/src/kudu/cfile/bitshuffle_arch_wrapper.cc b/src/kudu/cfile/bitshuffle_arch_wrapper.cc
index 4799cd5bc..b6ab94ceb 100644
--- a/src/kudu/cfile/bitshuffle_arch_wrapper.cc
+++ b/src/kudu/cfile/bitshuffle_arch_wrapper.cc
@@ -57,7 +57,7 @@ decltype(&bshuf_decompress_lz4) g_bshuf_decompress_lz4;
 // the cost of a 'std::once' call.
 __attribute__((constructor))
 void SelectBitshuffleFunctions() {
-#ifndef __APPLE__
+#if !defined(__APPLE__) && !defined(__aarch64__)
   if (CPU().has_avx2()) {
     g_bshuf_compress_lz4_bound = bshuf_compress_lz4_bound_avx2;
     g_bshuf_compress_lz4 = bshuf_compress_lz4_avx2;
diff --git a/src/kudu/util/group_varint-test.cc b/src/kudu/util/group_varint-test.cc
index 983fb0f36..faabb6d74 100644
--- a/src/kudu/util/group_varint-test.cc
+++ b/src/kudu/util/group_varint-test.cc
@@ -55,7 +55,7 @@ static void DoTestRoundTripGVI32(
   uint32_t ret[4];
 
   const uint8_t *end;
-
+#ifndef __aarch64__
   if (use_sse) {
     end = DecodeGroupVarInt32_SSE(
       buf.data(), &ret[0], &ret[1], &ret[2], &ret[3]);
@@ -63,7 +63,10 @@ static void DoTestRoundTripGVI32(
     end = DecodeGroupVarInt32(
       buf.data(), &ret[0], &ret[1], &ret[2], &ret[3]);
   }
-
+#else
+  end = DecodeGroupVarInt32(
+    buf.data(), &ret[0], &ret[1], &ret[2], &ret[3]);
+#endif
   ASSERT_EQ(a, ret[0]);
   ASSERT_EQ(b, ret[1]);
   ASSERT_EQ(c, ret[2]);
